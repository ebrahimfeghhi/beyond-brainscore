{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "base = '/home2/ebrahim/beyond-brainscore/'\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import sys\n",
    "sys.path.append(base)\n",
    "from plotting_functions import plot_across_subjects, plot_test_perf_across_layers, save_fMRI_simple, pass_info_plot_hist2d, find_rows_without_nan\n",
    "from trained_results_funcs import create_pd_selected_models, find_best, max_across_selected_models\n",
    "from trained_untrained_results_funcs import max_across_nested\n",
    "from scipy.stats import pearsonr\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from scipy.stats import ttest_rel, ttest_1samp\n",
    "import nibabel as nib\n",
    "from nilearn import plotting\n",
    "from nilearn import surface\n",
    "from nilearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2724271/1346510322.py:220: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "  plt.legend()\n"
     ]
    }
   ],
   "source": [
    "def find_best_sigma(sigma_range, noL2_str, exp, resultsPath, dataset, subjects, perf='pearson_r',\n",
    "                    lang_indices=None):\n",
    "    \n",
    "    '''\n",
    "    Finds best sigma value for OASM by taking the mean/median across subjects, and then taking \n",
    "    the mean across subjects.\n",
    "    '''\n",
    "\n",
    "    sigma_perf_dict = {}\n",
    "    \n",
    "    if dataset == 'pereira':\n",
    "        subjects = subjects[lang_indices]\n",
    "    \n",
    "    for s in sigma_range:\n",
    "        \n",
    "        s = round(s,3)\n",
    "        \n",
    "        # load in performance of OASM across voxels/electrodes/ROIs\n",
    "        OASM_perf =  np.load(f'{resultsPath}/{dataset}_OASM-all-sigma_{s}_1{noL2_str}{exp}.npz')[perf]\n",
    "        \n",
    "        OASM_perf = np.nan_to_num(OASM_perf, 0)\n",
    "    \n",
    "        \n",
    "        # if pereira, take median across language network voxels\n",
    "        # otherwise simply take the median\n",
    "        if dataset == 'pereira':\n",
    "            OASM_perf = OASM_perf[lang_indices]\n",
    "            \n",
    "            \n",
    "        OASM_subj = pd.DataFrame({'perf': OASM_perf, 'subject': subjects})\n",
    "        \n",
    "        if perf == 'pearson_r':\n",
    "            perf_avg = np.median(OASM_subj.groupby['subject'].median())\n",
    "        else:\n",
    "            perf_avg = np.mean(OASM_subj.groupby['subject'].mean())\n",
    "    \n",
    "        # make sure it's not nan, happens sometimes when sigma is low \n",
    "        # not totally sure why \n",
    "        if ~np.isnan(perf_avg):\n",
    "            sigma_perf_dict[s] = perf_avg\n",
    "        \n",
    "    best_sigma = max(sigma_perf_dict, key=sigma_perf_dict.get)\n",
    "    \n",
    "    OASM_perf_best =  np.load(f'{resultsPath}/{dataset}_OASM-all-sigma_{best_sigma}_1{noL2_str}{exp}.npz')[perf]\n",
    "    OASM_perf_best = np.nan_to_num(OASM_perf_best, 0)\n",
    "        \n",
    "    return sigma_perf_dict, best_sigma, OASM_perf_best\n",
    "\n",
    "def find_best_layer(layer_range, noL2_str, exp, resultsPath, subjects, dataset, perf='pearson_r', \n",
    "                    lang_indices = None):\n",
    "    \n",
    "\n",
    "    layer_perf_dict = {}\n",
    "    \n",
    "    if dataset == 'pereira':\n",
    "        subjects = subjects[lang_indices]\n",
    "    \n",
    "    for l in layer_range:\n",
    "    \n",
    "        layer_perf =  np.load(f'{resultsPath}/{dataset}_gpt2-xl_layer_{l}_1{noL2_str}{exp}.npz')[perf]\n",
    "        \n",
    "        if perf != 'pearson_r':\n",
    "            layer_perf = np.clip(layer_perf, 0, np.inf)\n",
    "        \n",
    "        layer_perf = np.nan_to_num(layer_perf, nan=0)\n",
    "        \n",
    "        if dataset == 'pereira':\n",
    "            layer_perf = layer_perf[lang_indices]\n",
    "            \n",
    "            \n",
    "        layer_subject = pd.DataFrame({'perf': layer_perf, 'subject': subjects})    \n",
    "    \n",
    "        if perf == 'pearson_r':\n",
    "            perf_avg = np.median(layer_subject.groupby(['subject']).median())\n",
    "        else:\n",
    "            perf_avg = np.mean(layer_subject.groupby(['subject']).mean())\n",
    "        \n",
    "        layer_perf_dict[l] = perf_avg\n",
    "            \n",
    "    best_layer = max(layer_perf_dict, key=layer_perf_dict.get)\n",
    "    \n",
    "    layer_perf_best =  np.load(f'{resultsPath}/{dataset}_gpt2-xl_layer_{best_layer}_1{noL2_str}{exp}.npz')[perf]\n",
    "    layer_perf_best = np.nan_to_num(layer_perf_best, 0)\n",
    "        \n",
    "    return layer_perf_dict, best_layer, layer_perf_best    \n",
    "\n",
    "noL2_arr = [False]\n",
    "shuffled_arr = [False]\n",
    "dataset_arr = ['fedorenko']\n",
    "perf_arr = ['pearson_r']\n",
    "\n",
    "for perf in perf_arr:\n",
    "    for noL2 in noL2_arr:\n",
    "        for shuffled in shuffled_arr:\n",
    "            for dataset in dataset_arr:\n",
    "                \n",
    "                if noL2:\n",
    "                    noL2_str = '_noL2'\n",
    "                else:\n",
    "                    noL2_str = ''\n",
    "                    \n",
    "                if shuffled:\n",
    "                    shuffled_str = '_shuffled'\n",
    "                else:\n",
    "                    shuffled_str = ''\n",
    "\n",
    "                \n",
    "                resultsPath_dataset_nonshuffled = f'/data/LLMs/brainscore/results_{dataset}'\n",
    "                if shuffled:\n",
    "                    resultsPath_dataset = f'/data/LLMs/brainscore/results_{dataset}/shuffled'\n",
    "                else:\n",
    "                    resultsPath_dataset = resultsPath_dataset_nonshuffled\n",
    "                data_processed_folder = f'/data/LLMs/data_processed/{dataset}/dataset'\n",
    "                figurePath = '/home2/ebrahim/beyond-brainscore/analyze_results/figures_code/figures/new_figures/figure1/'\n",
    "                figurePath = f'{figurePath}{perf}/'\n",
    "                default_palette = sns.color_palette('deep')   \n",
    "\n",
    "        \n",
    "                # load information regarding number of voxels, subjects, and functional network localization for each experiment into a dictionary\n",
    "                if dataset ==  'pereira':\n",
    "\n",
    "                    exp = ['243', '384']\n",
    "\n",
    "                    br_labels_dict = {}\n",
    "                    num_vox_dict = {}\n",
    "                    subjects_dict = {}\n",
    "                    for e in exp:\n",
    "\n",
    "                        bre = np.load(f'{data_processed_folder}/networks_{e}.npy', allow_pickle=True)\n",
    "                        br_labels_dict[e] = bre\n",
    "                        num_vox_dict[e] = bre.shape[0]\n",
    "                        subjects_dict[e] = np.load(f\"{data_processed_folder}/subjects_{e}.npy\", allow_pickle=True)\n",
    "                        \n",
    "                    lang_indices_384 = np.argwhere(br_labels_dict['384'] == 'language').squeeze()\n",
    "                    lang_indices_243 = np.argwhere(br_labels_dict['243'] == 'language').squeeze()\n",
    "                    \n",
    "                else:\n",
    "                    subjects_arr  = np.load(f\"{data_processed_folder}/subjects.npy\", allow_pickle=True)\n",
    "                    \n",
    "\n",
    "                if shuffled:\n",
    "                    # script crashes at sigma of 4.3 in fed due to an issue with linear reg converging\n",
    "                    if dataset == 'fedorenko' and shuffled:\n",
    "                        sigma_values = np.linspace(0.1, 4.2, 42)\n",
    "                    else:\n",
    "                        sigma_values = np.linspace(0.1, 4.8, 48)\n",
    "                                \n",
    "                    if dataset == 'pereira':\n",
    "                        sigma_perf_dict_384, best_sigma_384, OASM_perf_best_sigma_384 = find_best_sigma(sigma_values, noL2_str=noL2_str, exp='_384', subjects=subjects_dict['384'], \n",
    "                                                                        resultsPath=resultsPath_dataset, dataset=dataset, lang_indices=lang_indices_384, \n",
    "                                                                        perf=perf)   \n",
    "                        sigma_perf_dict_243, best_sigma_243, OASM_perf_best_sigma_243 = find_best_sigma(sigma_values, noL2_str=noL2_str, exp='_243', subjects=subjects_dict['243'], \n",
    "                                                                        resultsPath=resultsPath_dataset, dataset=dataset, lang_indices=lang_indices_243, \n",
    "                                                                        perf=perf)\n",
    "                    else:\n",
    "                        sigma_perf_dict, best_sigma, OASM_perf_best_sigma = find_best_sigma(sigma_values, noL2_str=noL2_str, exp='', subjects=subjects_arr, resultsPath=resultsPath_dataset, dataset=dataset, perf=perf)\n",
    "                        \n",
    "                    if dataset == 'pereira':\n",
    "                        plt.plot(sigma_perf_dict_384.keys(), sigma_perf_dict_384.values(), label='384')\n",
    "                        plt.plot(sigma_perf_dict_243.keys(), sigma_perf_dict_243.values(), label='243')\n",
    "                    else:\n",
    "                        plt.plot(sigma_perf_dict.keys(), sigma_perf_dict.values())\n",
    "                        \n",
    "                    plt.legend()\n",
    "                    plt.xlabel(\"Sigma values\")\n",
    "                    plt.ylabel(\"Median pearson r across language voxels\")\n",
    "                    plt.savefig(f\"{figurePath}across_layer/across_layer_OASM_{dataset}{noL2_str}{shuffled_str}\")\n",
    "                    plt.close()\n",
    "                \n",
    "                else:\n",
    "                    \n",
    "                    if dataset == 'pereira':\n",
    "                        \n",
    "                        simple_perf_384 =  np.load(f'{resultsPath_dataset}/{dataset}_positional_WN_layer1_1{noL2_str}_384.npz')[perf]\n",
    "                        simple_perf_243 =  np.load(f'{resultsPath_dataset}/{dataset}_positional_WN_layer1_1{noL2_str}_243.npz')[perf]\n",
    "                        \n",
    "                    if dataset == 'fedorenko':\n",
    "        \n",
    "                        simple_perf =  np.load(f'{resultsPath_dataset}/{dataset}_soft+grow_layer1_1{noL2_str}.npz')[perf]\n",
    "                        \n",
    "                \n",
    "                if dataset == 'pereira':\n",
    "                    gpt2_xl_384_dict, gpt2_xl_384_bl, gpt2_xl_384_bl_perf = find_best_layer(np.arange(0,49), noL2_str=noL2_str, exp='_384', \n",
    "                                                                                            resultsPath=resultsPath_dataset, lang_indices=lang_indices_384, dataset=dataset, \n",
    "                                                                                            subjects=subjects_dict['384'], perf=perf)\n",
    "                    gpt2_xl_243_dict, gpt2_xl_243_bl, gpt2_xl_243_bl_perf = find_best_layer(np.arange(0,49), noL2_str=noL2_str, exp='_243', \n",
    "                                                                                            resultsPath=resultsPath_dataset, lang_indices=lang_indices_243, dataset=dataset, \n",
    "                                                                                            subjects=subjects_dict['243'], perf=perf)\n",
    "                else:\n",
    "                    gpt2_xl_dict, gpt2_xl_bl, gpt2_xl_bl_perf = find_best_layer(np.arange(0,49), noL2_str=noL2_str, exp='', subjects=subjects_arr, resultsPath=resultsPath_dataset, dataset=dataset, perf=perf)\n",
    "\n",
    "                \n",
    "                if dataset == 'pereira':\n",
    "                    plt.plot(gpt2_xl_384_dict.keys(), gpt2_xl_384_dict.values(), label='384')\n",
    "                    plt.plot(gpt2_xl_243_dict.keys(), gpt2_xl_243_dict.values(), label='243')\n",
    "                else:\n",
    "                    plt.plot(gpt2_xl_dict.keys(), gpt2_xl_dict.values())\n",
    "                plt.legend()\n",
    "                plt.xlabel(\"Layer number\")\n",
    "                plt.ylabel(\"Median pearson r across language voxels\")\n",
    "                plt.savefig(f\"{figurePath}across_layer/across_layer_GPT2XL_{dataset}{noL2_str}{shuffled_str}\")\n",
    "                plt.close()\n",
    "                \n",
    "        \n",
    "                if dataset == 'pereira':\n",
    "                    \n",
    "                    if shuffled:\n",
    "                        results_dict_simple_384 = pd.DataFrame({'perf': OASM_perf_best_sigma_384, 'subjects': subjects_dict['384'], \n",
    "                                        'Network': br_labels_dict['384'], 'Model': np.repeat('OASM', num_vox_dict['384'])})\n",
    "                        results_dict_simple_243 = pd.DataFrame({'perf': OASM_perf_best_sigma_243, 'subjects': subjects_dict['243'], \n",
    "                                        'Network': br_labels_dict['243'], 'Model': np.repeat('OASM', num_vox_dict['243'])})\n",
    "                        \n",
    "                    else:\n",
    "                        results_dict_simple_384 = pd.DataFrame({'perf': simple_perf_384, 'subjects': subjects_dict['384'], \n",
    "                                        'Network': br_labels_dict['384'], 'Model': np.repeat('SP+SL', num_vox_dict['384'])})\n",
    "                        results_dict_simple_243 = pd.DataFrame({'perf': simple_perf_243, 'subjects': subjects_dict['243'], \n",
    "                                        'Network': br_labels_dict['243'], 'Model': np.repeat('SP+SL', num_vox_dict['243'])})\n",
    "                        \n",
    "                    results_dict_gpt2_384 = pd.DataFrame({'perf': gpt2_xl_384_bl_perf, 'subjects': subjects_dict['384'], \n",
    "                                    'Network': br_labels_dict['384'], 'Model': np.repeat('GPT2-XL', num_vox_dict['384'])})\n",
    "                    results_dict_gpt2_243 = pd.DataFrame({'perf': gpt2_xl_243_bl_perf, 'subjects': subjects_dict['243'], \n",
    "                                    'Network': br_labels_dict['243'], 'Model': np.repeat('GPT2-XL', num_vox_dict['243'])})\n",
    "\n",
    "                    results_simple_gpt2xl_243 = pd.concat((results_dict_simple_243, results_dict_gpt2_243))\n",
    "                    results_simple_gpt2xl_384 = pd.concat((results_dict_simple_384, results_dict_gpt2_384))\n",
    "                    \n",
    "                else:\n",
    "                    num_brain_units = gpt2_xl_bl_perf.shape[0]\n",
    "                    \n",
    "                    if shuffled:\n",
    "                        results_dict_simple = pd.DataFrame({'perf': OASM_perf_best_sigma, 'subjects': subjects_arr, 'Network': np.repeat('language', num_brain_units),\n",
    "                                                    'Model': np.repeat('OASM', num_brain_units)})\n",
    "                    else:\n",
    "                        \n",
    "                        if dataset == 'fedorenko':\n",
    "                            results_dict_simple = pd.DataFrame({'perf': simple_perf, 'subjects': subjects_arr, 'Network': np.repeat('language', num_brain_units),\n",
    "                                                    'Model': np.repeat('WP', num_brain_units)})\n",
    "\n",
    "                    results_dict_gpt2 = pd.DataFrame({'perf': gpt2_xl_bl_perf, 'subjects': subjects_arr, 'Network': np.repeat('language', num_brain_units),\n",
    "                                                    'Model': np.repeat('GPT2-XL', num_brain_units)})\n",
    "                    \n",
    "                    if shuffled or dataset == 'fedorenko':\n",
    "                        results_simple_gpt2xl = pd.concat((results_dict_simple, results_dict_gpt2))\n",
    "                    \n",
    "                \n",
    "                if perf == 'pearson_r':\n",
    "                    median = True\n",
    "                    clip_zero = False\n",
    "                    perf_str = 'Pearson r'\n",
    "                else:\n",
    "                    median = False\n",
    "                    clip_zero = True\n",
    "                    perf_str = r'$R^2$'\n",
    "                    \n",
    "                if shuffled:\n",
    "                    cidx_p = 9\n",
    "                    cidx_fb = 9\n",
    "                else:\n",
    "                    cidx_p = 7\n",
    "                    cidx_fb = 6\n",
    "                    \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.028446108262522935"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject_avg_pd_243_pd = subject_avg_pd_243.reset_index()\n",
    "subject_avg_pd_243_pd.loc[subject_avg_pd_243_pd.Model=='GPT2-XL']['perf'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_brain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
