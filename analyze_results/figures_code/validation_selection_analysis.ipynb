{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('/home3/ebrahim2/beyond-brainscore/run_reg_scripts/')\n",
    "from helper_funcs import combine_MSE_across_folds\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def _mean_across_participants(values_per_unit, participant_info):\n",
    "    \"\"\"\n",
    "    values_per_unit: 1D array, length = # brain units (e.g., R² per unit)\n",
    "    participant_info: 1D array, length = # brain units, giving participant id per unit\n",
    "\n",
    "    Returns:\n",
    "      overall_mean: scalar mean of per-participant means (ignores NaNs)\n",
    "      per_participant_means: dict {participant_id: mean_value}\n",
    "    \"\"\"\n",
    "    vals = np.asarray(values_per_unit)\n",
    "    parts = np.asarray(participant_info)\n",
    "    per_part_means = {}\n",
    "    for pid in np.unique(parts):\n",
    "        mask = (parts == pid)\n",
    "        if np.any(mask):\n",
    "            per_part_means[pid] = np.clip(np.nanmean(vals[mask]), 0, np.inf)\n",
    "    overall = np.nanmean(list(per_part_means.values())) if per_part_means else np.nan\n",
    "    return overall, per_part_means\n",
    "\n",
    "\n",
    "def compare_perf_when_using_val(\n",
    "    dataset,\n",
    "    y_true,\n",
    "    test_fold_idx,\n",
    "    layer_range,\n",
    "    mse_intercept,\n",
    "    model_name,\n",
    "    model_name_y_hat,\n",
    "    participant_info,\n",
    "    shuffled=False, \n",
    "    return_participant_means=False\n",
    "):\n",
    "    \"\"\"\n",
    "    participant_info: shape (# brain units,), contains the participant id\n",
    "                      for the corresponding brain unit.\n",
    "    \"\"\"\n",
    "    val_scores_across_layers = []\n",
    "    test_score = []\n",
    "    per_part_mean_test = []\n",
    "\n",
    "    base_path = f'/data/LLMs/brainscore/results_{dataset}/'\n",
    "    if shuffled:\n",
    "        base_path += 'shuffled/'\n",
    "\n",
    "    # loop through model layers/hyperparameters\n",
    "    for ln in layer_range:\n",
    "        # replace -1 with the layer name\n",
    "        model_name_ln = model_name.replace('-1', f'{ln}')\n",
    "\n",
    "        # val_scores: (num_outer_folds x num_units); we keep your original averaging across units\n",
    "        val_scores = np.mean(\n",
    "            np.load(f'{base_path}{dataset}_{model_name_ln}.npz')['val_scores'],\n",
    "            axis=-1\n",
    "        )\n",
    "        val_scores_across_layers.append(val_scores)\n",
    "\n",
    "        # --- TEST (on test set) ---\n",
    "        # out_of_sample_r2: (num_units)\n",
    "        oos_r2_units = np.load(f'{base_path}{dataset}_{model_name_ln}.npz')['out_of_sample_r2']\n",
    "        # mean within each participant, then across participants\n",
    "        layer_mean, per_part_mean = _mean_across_participants(oos_r2_units, participant_info)\n",
    "        test_score.append(layer_mean)\n",
    "        per_part_mean_test.append(per_part_mean)\n",
    "\n",
    "    # Pick best layer per fold from validation\n",
    "    val_scores_across_layers_stacked = np.vstack(val_scores_across_layers)  # (num_layers x num_folds)\n",
    "    best_val_layers = np.argmax(val_scores_across_layers_stacked, axis=0)   # (num_folds,)\n",
    "    stacked_mse = []\n",
    "\n",
    "    for idx, bvl_idx in enumerate(best_val_layers):\n",
    "        # compute mse for the best layer selected from that outer fold\n",
    "        bvl = layer_range[bvl_idx]\n",
    "        model_name_bvl = model_name_y_hat.replace('-1', f'{bvl}')\n",
    "        y_hat = np.load(f'{base_path}{dataset}_{model_name_bvl}.npz')['y_hat']\n",
    "        mse = (y_true - y_hat) ** 2\n",
    "\n",
    "        # only take the mse values for the outer fold range\n",
    "        start_idx = test_fold_idx[idx]\n",
    "        end_idx = test_fold_idx[idx + 1]\n",
    "        stacked_mse.append(mse[start_idx:end_idx])\n",
    "\n",
    "    # np.vstack(stacked_mse): (time x brain units); mean across time -> (brain units,)\n",
    "    stacked_mse_np = np.mean(np.vstack(stacked_mse), axis=0)\n",
    "    out_of_sample_r2_by_val = 1 - stacked_mse_np / mse_intercept  # (brain units,)\n",
    "\n",
    "    # --- PRINTS with per-participant aggregation ---\n",
    "    val_overall_mean, per_part_means_val = _mean_across_participants(out_of_sample_r2_by_val, participant_info)\n",
    "    print(\"Performance when using val to select best layer/hparam (per-participant mean, then across participants):\",\n",
    "          val_overall_mean)\n",
    "\n",
    "    print(\"Performance when using test set (best layer by test R², per-participant mean, then across participants):\",\n",
    "          np.nanmax(test_score))\n",
    "    \n",
    "    if return_participant_means:\n",
    "        best_layer = np.nanargmax(test_score)\n",
    "        return test_score, val_scores_across_layers_stacked, per_part_mean_test[best_layer], per_part_means_val\n",
    "        \n",
    "\n",
    "    return test_score, val_scores_across_layers_stacked\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2-XL, SHUFFLED, PEREIRA 384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_589291/328599151.py:86: RuntimeWarning: invalid value encountered in divide\n",
      "  out_of_sample_r2_by_val = 1 - stacked_mse_np / mse_intercept  # (brain units,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance when using val to select best layer/hparam (per-participant mean, then across participants): 0.1715490221977234\n",
      "Performance when using test set (best layer by test R², per-participant mean, then across participants): 0.17154901736921307\n",
      "OASM, SHUFFLED, PEREIRA 384\n",
      "Performance when using val to select best layer/hparam (per-participant mean, then across participants): 0.22679586542977226\n",
      "Performance when using test set (best layer by test R², per-participant mean, then across participants): 0.22747532839740478\n"
     ]
    }
   ],
   "source": [
    "y_true_shuffled = np.load('/data/LLMs/brainscore/results_pereira/shuffled/y_test_ordered_384_lang.npy')\n",
    "test_fold_size_shuffled = np.load('/data/LLMs/brainscore/results_pereira/shuffled/test_fold_size_384.npy')\n",
    "test_fold_idx_shuffled = np.hstack(([0], np.cumsum(test_fold_size_shuffled)))\n",
    "mse_intercept_shuffled = np.mean(np.load('/data/LLMs/brainscore/results_pereira/shuffled/mse_intercept_384_lang.npy'),axis=0)\n",
    "subjects_384 = np.load('/data/LLMs/data_processed/pereira/dataset/subjects_384_lang.npy', allow_pickle=True)\n",
    "\n",
    "\n",
    "print(\"GPT2-XL, SHUFFLED, PEREIRA 384\")\n",
    "ts_gpt, vs_gpt, pt_gpt, pv_gpt = compare_perf_when_using_val('pereira', y_true_shuffled, \n",
    "                            test_fold_idx_shuffled, \n",
    "                            np.arange(49), \n",
    "                            mse_intercept_shuffled,\n",
    "                            'gpt2-xl_layer_-1_1_384_m0', 'gpt2-xl_layer_-1_1_384_m0', subjects_384, shuffled=True, return_participant_means=True)\n",
    "\n",
    "print(\"OASM, SHUFFLED, PEREIRA 384\")\n",
    "ts, vs, pt_oasm, pv_oasm = compare_perf_when_using_val('pereira', y_true_shuffled, \n",
    "                            test_fold_idx_shuffled, \n",
    "                            np.round(np.arange(0.1,4.8,0.1),3), \n",
    "                            mse_intercept_shuffled,\n",
    "                            'OASM-all-sigma_-1_1_384', 'OASM-all-sigma_-1_1_384', subjects_384, shuffled=True, return_participant_means=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2-XL, SHUFFLED, PEREIRA 243\n",
      "Performance when using val to select best layer/hparam (per-participant mean, then across participants): 0.12202912320693333\n",
      "Performance when using test set (best layer by test R², per-participant mean, then across participants): 0.12202912389656732\n",
      "OASM, SHUFFLED, PEREIRA 243\n",
      "Performance when using val to select best layer/hparam (per-participant mean, then across participants): 0.18252869447072348\n",
      "Performance when using test set (best layer by test R², per-participant mean, then across participants): 0.18359714245434736\n"
     ]
    }
   ],
   "source": [
    "y_true_shuffled = np.load('/data/LLMs/brainscore/results_pereira/shuffled/y_test_ordered_243_lang.npy')\n",
    "test_fold_size_shuffled = np.load('/data/LLMs/brainscore/results_pereira/shuffled/test_fold_size_243.npy')\n",
    "test_fold_idx_shuffled = np.hstack(([0], np.cumsum(test_fold_size_shuffled)))\n",
    "mse_intercept_shuffled = np.mean(np.load('/data/LLMs/brainscore/results_pereira/shuffled/mse_intercept_243_lang.npy'),axis=0)\n",
    "subjects_243 = np.load('/data/LLMs/data_processed/pereira/dataset/subjects_243_lang.npy', allow_pickle=True)\n",
    "\n",
    "print(\"GPT2-XL, SHUFFLED, PEREIRA 243\")\n",
    "ts_gpt, vs_gpt, pt_gpt_243, pv_gpt_243 = compare_perf_when_using_val('pereira', y_true_shuffled, \n",
    "                            test_fold_idx_shuffled, \n",
    "                            np.arange(49), \n",
    "                            mse_intercept_shuffled,\n",
    "                            'gpt2-xl_layer_-1_1_243_m2', 'gpt2-xl_layer_-1_1_243_m2', subjects_243, shuffled=True, return_participant_means=True)\n",
    "\n",
    "print(\"OASM, SHUFFLED, PEREIRA 243\")\n",
    "ts, vs, pt_oasm_243, pv_oasm_243 = compare_perf_when_using_val('pereira', y_true_shuffled, \n",
    "                            test_fold_idx_shuffled, \n",
    "                            np.round(np.arange(0.1,4.8,0.1),3), \n",
    "                            mse_intercept_shuffled,\n",
    "                            'OASM-all-sigma_-1_1_243', 'OASM-all-sigma_-1_1_243', subjects_243, shuffled=True, return_participant_means=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OASM validation: 0.2146851658821106\n",
      "GPT2 Validation Shuffled: 0.15399813018739222\n",
      "OASM test: 0.21566910575181578\n",
      "GPT2 test Shuffled: 0.15399812704523427\n"
     ]
    }
   ],
   "source": [
    "def merge_dicts_mean(d1, d2, message):\n",
    "    \"\"\"\n",
    "    Merge two dicts by taking the mean of values for shared keys.\n",
    "    If a key is unique to one dict, keep its value.\n",
    "    \n",
    "    Args:\n",
    "        d1 (dict): First dictionary with numeric values\n",
    "        d2 (dict): Second dictionary with numeric values\n",
    "    \n",
    "    Returns:\n",
    "        dict: Merged dictionary\n",
    "    \"\"\"\n",
    "    merged = {}\n",
    "    all_keys = set(d1.keys()) | set(d2.keys())\n",
    "    \n",
    "    for k in all_keys:\n",
    "        if k in d1 and k in d2:\n",
    "            merged[k] = (d1[k] + d2[k]) / 2\n",
    "        elif k in d1:\n",
    "            merged[k] = d1[k]\n",
    "        else:\n",
    "            merged[k] = d2[k]\n",
    "    \n",
    "    print(f\"{message}: {np.mean(list(merged.values()))}\")\n",
    "\n",
    "merge_dicts_mean(pv_oasm, pv_oasm_243, \"OASM validation\")\n",
    "merge_dicts_mean(pv_gpt, pv_gpt_243, \"GPT2 Validation Shuffled\")\n",
    "\n",
    "merge_dicts_mean(pt_oasm, pt_oasm_243, \"OASM test\")\n",
    "merge_dicts_mean(pt_gpt, pt_gpt_243, \"GPT2 test Shuffled\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2-XL,PEREIRA 384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_589291/328599151.py:86: RuntimeWarning: invalid value encountered in divide\n",
      "  out_of_sample_r2_by_val = 1 - stacked_mse_np / mse_intercept  # (brain units,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance when using val to select best layer/hparam (per-participant mean, then across participants): 0.027326632084117994\n",
      "Performance when using test set (best layer by test R², per-participant mean, then across participants): 0.029126123267106334\n",
      "Position, PEREIRA 384\n",
      "Performance when using val to select best layer/hparam (per-participant mean, then across participants): 0.011171347633030059\n",
      "Performance when using test set (best layer by test R², per-participant mean, then across participants): 0.011746037433222042\n"
     ]
    }
   ],
   "source": [
    "y_true = np.load('/data/LLMs/brainscore/results_pereira/y_test_ordered_384_lang.npy')\n",
    "test_fold_size = np.load('/data/LLMs/brainscore/results_pereira/test_fold_size_384.npy')\n",
    "test_fold_idx = np.hstack(([0], np.cumsum(test_fold_size)))\n",
    "mse_intercept = np.mean(np.load('/data/LLMs/brainscore/results_pereira/mse_intercept_384_lang.npy'),axis=0)\n",
    "\n",
    "\n",
    "print(\"GPT2-XL,PEREIRA 384\")\n",
    "ts_gpt, vs_gpt, pt_gpt, pv_gpt = compare_perf_when_using_val('pereira', y_true, \n",
    "                            test_fold_idx, \n",
    "                            np.arange(49), \n",
    "                            mse_intercept,\n",
    "                            'gpt2-xl_layer_-1_1_384', 'gpt2-xl_layer_-1_1_384', subjects_384, shuffled=False, return_participant_means=True)\n",
    "\n",
    "print(\"Position, PEREIRA 384\")\n",
    "ts, vs, pt_pos, pv_pos = compare_perf_when_using_val('pereira', y_true, \n",
    "                            test_fold_idx, \n",
    "                            np.round(np.arange(0.1,4.8,0.1),3), \n",
    "                            mse_intercept,\n",
    "                            'position_layer_-1_1_384', 'position_layer_-1_1_384', subjects_384, shuffled=False, return_participant_means=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2-XL,PEREIRA 243\n",
      "Performance when using val to select best layer/hparam (per-participant mean, then across participants): 0.02026554204834004\n",
      "Performance when using test set (best layer by test R², per-participant mean, then across participants): 0.02285006216048691\n",
      "Position, PEREIRA 243\n",
      "Performance when using val to select best layer/hparam (per-participant mean, then across participants): 0.005398740021822353\n",
      "Performance when using test set (best layer by test R², per-participant mean, then across participants): 0.005938581932922522\n"
     ]
    }
   ],
   "source": [
    "y_true= np.load('/data/LLMs/brainscore/results_pereira/y_test_ordered_243_lang.npy')\n",
    "test_fold_size = np.load('/data/LLMs/brainscore/results_pereira/test_fold_size_243.npy')\n",
    "test_fold_idx = np.hstack(([0], np.cumsum(test_fold_size)))\n",
    "mse_intercept = np.mean(np.load('/data/LLMs/brainscore/results_pereira/mse_intercept_243_lang.npy'),axis=0)\n",
    "\n",
    "\n",
    "print(\"GPT2-XL,PEREIRA 243\")\n",
    "ts_gpt, vs_gpt, pt_gpt_243, pv_gpt_243 = compare_perf_when_using_val('pereira', y_true, \n",
    "                            test_fold_idx, \n",
    "                            np.arange(49), \n",
    "                            mse_intercept,\n",
    "                            'gpt2-xl_layer_-1_1_243', 'gpt2-xl_layer_-1_1_243', subjects_243, shuffled=False, return_participant_means=True)\n",
    "\n",
    "print(\"Position, PEREIRA 243\")\n",
    "ts, vs, pt_pos_243, pv_pos_243 = compare_perf_when_using_val('pereira', y_true, \n",
    "                            test_fold_idx, \n",
    "                            np.round(np.arange(0.1,4.8,0.1),3), \n",
    "                            mse_intercept,\n",
    "                            'position_layer_-1_1_243', 'position_layer_-1_1_243', subjects_243, shuffled=False, return_participant_means=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS validation: 0.009187782190565486\n",
      "GPT2 Validation: 0.021470996527932586\n",
      "POS test: 0.009743077554318092\n",
      "GPT2 test: 0.02321203350659032\n"
     ]
    }
   ],
   "source": [
    "\n",
    "merge_dicts_mean(pv_pos, pv_pos_243, \"POS validation\")\n",
    "merge_dicts_mean(pv_gpt, pv_gpt_243, \"GPT2 Validation\")\n",
    "\n",
    "merge_dicts_mean(pt_pos, pt_pos_243, \"POS test\")\n",
    "merge_dicts_mean(pt_gpt, pt_gpt_243, \"GPT2 test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2-XL, SHUFFLED, FEDORENKO\n",
      "Performance when using val to select best layer/hparam (per-participant mean, then across participants): 0.08362601026892662\n",
      "Performance when using test set (best layer by test R², per-participant mean, then across participants): 0.0854775407576281\n",
      "OASM, SHUFFLED, FEDORENKO\n",
      "Performance when using val to select best layer/hparam (per-participant mean, then across participants): 0.09688139706850052\n",
      "Performance when using test set (best layer by test R², per-participant mean, then across participants): 0.09788830144179941\n"
     ]
    }
   ],
   "source": [
    "results_dir = \"results_fedorenko\"  # or any other directory you want\n",
    "\n",
    "y_true_shuffled = np.load(f\"/data/LLMs/brainscore/{results_dir}/shuffled/y_test_ordered.npy\")\n",
    "test_fold_size_shuffled = np.load(f\"/data/LLMs/brainscore/{results_dir}/shuffled/test_fold_size.npy\")\n",
    "test_fold_idx_shuffled = np.hstack(([0], np.cumsum(test_fold_size_shuffled)))\n",
    "mse_intercept_shuffled = np.mean(\n",
    "    np.load(f\"/data/LLMs/brainscore/{results_dir}/shuffled/mse_intercept.npy\"), axis=0\n",
    ")\n",
    "\n",
    "subjects_fed = np.load('/data/LLMs/data_processed/fedorenko/dataset/subjects.npy', allow_pickle=True)\n",
    "\n",
    "\n",
    "print(\"GPT2-XL, SHUFFLED, FEDORENKO\")\n",
    "ts_gpt, vs_gpt = compare_perf_when_using_val('fedorenko', y_true_shuffled, \n",
    "                            test_fold_idx_shuffled, \n",
    "                            np.arange(49), \n",
    "                            mse_intercept_shuffled,\n",
    "                            'gpt2-xl_layer_-1_1', 'gpt2-xl_layer_-1_1', subjects_fed, shuffled=True)\n",
    "\n",
    "\n",
    "print(\"OASM, SHUFFLED, FEDORENKO\")\n",
    "ts_gpt, vs_gpt = compare_perf_when_using_val('fedorenko', y_true_shuffled, \n",
    "                            test_fold_idx_shuffled, \n",
    "                            np.round(np.arange(0.1,4.8,0.1),3), \n",
    "                            mse_intercept_shuffled,\n",
    "                            'OASM-all-sigma_-1_1', 'OASM-all-sigma_-1_1', subjects_fed, shuffled=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2-XL, NOT SHUFFLED, FEDORENKO\n",
      "Performance when using val to select best layer/hparam (per-participant mean, then across participants): 0.048867734521627425\n",
      "Performance when using test set (best layer by test R², per-participant mean, then across participants): 0.05085057621718514\n",
      "POS, NOT SHUFFLED, FEDORENKO\n",
      "Performance when using val to select best layer/hparam (per-participant mean, then across participants): 0.04647891782224178\n",
      "Performance when using test set (best layer by test R², per-participant mean, then across participants): 0.047141644278820984\n"
     ]
    }
   ],
   "source": [
    "results_dir = \"results_fedorenko\"  # or any other directory you want\n",
    "shuffled = False  # set True/False here\n",
    "\n",
    "# decide subfolder based on shuffled flag\n",
    "subdir = \"shuffled\" if shuffled else \"\"\n",
    "\n",
    "# add \"/\" only if needed\n",
    "folder = f\"/{subdir}\" if subdir else \"\"\n",
    "\n",
    "y_true = np.load(f\"/data/LLMs/brainscore/{results_dir}{folder}/y_test_ordered.npy\")\n",
    "test_fold_size = np.load(f\"/data/LLMs/brainscore/{results_dir}{folder}/test_fold_size.npy\")\n",
    "test_fold_idx = np.hstack(([0], np.cumsum(test_fold_size)))\n",
    "mse_intercept = np.mean(\n",
    "    np.load(f\"/data/LLMs/brainscore/{results_dir}{folder}/mse_intercept.npy\"), axis=0\n",
    ")\n",
    "\n",
    "subjects_fed = np.load('/data/LLMs/data_processed/fedorenko/dataset/subjects.npy', allow_pickle=True)\n",
    "\n",
    "print(f\"GPT2-XL, {'SHUFFLED' if shuffled else 'NOT SHUFFLED'}, FEDORENKO\")\n",
    "ts_gpt, vs_gpt = compare_perf_when_using_val(\n",
    "    'fedorenko',\n",
    "    y_true,\n",
    "    test_fold_idx,\n",
    "    np.arange(49),\n",
    "    mse_intercept,\n",
    "    'gpt2-xl_layer_-1_1',\n",
    "    'gpt2-xl_layer_-1_1',\n",
    "    subjects_fed,\n",
    "    shuffled=shuffled\n",
    ")\n",
    "\n",
    "print(f\"POS, {'SHUFFLED' if shuffled else 'NOT SHUFFLED'}, FEDORENKO\")\n",
    "ts_gpt, vs_gpt = compare_perf_when_using_val(\n",
    "    'fedorenko',\n",
    "    y_true,\n",
    "    test_fold_idx,\n",
    "    np.round(np.arange(0.1, 4.8, 0.1), 3),\n",
    "    mse_intercept,\n",
    "    'pos_layer_-1_1',\n",
    "    'pos_layer_-1_1',\n",
    "    subjects_fed,\n",
    "    shuffled=shuffled\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2-XL, SHUFFLED, BLANK\n",
      "Performance when using val to select best layer/hparam (per-participant mean, then across participants): 0.0017078061355277896\n",
      "Performance when using test set (best layer by test R², per-participant mean, then across participants): 0.002857624729844399\n",
      "OASM, SHUFFLED, BLANK\n",
      "Performance when using val to select best layer/hparam (per-participant mean, then across participants): 0.2747193992137909\n",
      "Performance when using test set (best layer by test R², per-participant mean, then across participants): 0.27495304508994145\n"
     ]
    }
   ],
   "source": [
    "results_dir = \"results_blank\"  # or any other directory you want\n",
    "\n",
    "y_true_shuffled = np.load(f\"/data/LLMs/brainscore/{results_dir}/shuffled/y_test_ordered.npy\")\n",
    "test_fold_size_shuffled = np.load(f\"/data/LLMs/brainscore/{results_dir}/shuffled/test_fold_size.npy\")\n",
    "test_fold_idx_shuffled = np.hstack(([0], np.cumsum(test_fold_size_shuffled)))\n",
    "mse_intercept_shuffled = np.mean(\n",
    "    np.load(f\"/data/LLMs/brainscore/{results_dir}/shuffled/mse_intercept.npy\"), axis=0\n",
    ")\n",
    "subjects_blank = np.load('/data/LLMs/data_processed/blank/dataset/subjects.npy', allow_pickle=True)\n",
    "\n",
    "\n",
    "\n",
    "print(\"GPT2-XL, SHUFFLED, BLANK\")\n",
    "_, _ = compare_perf_when_using_val('blank', y_true_shuffled, \n",
    "                            test_fold_idx_shuffled, \n",
    "                            np.arange(48), \n",
    "                            mse_intercept_shuffled,\n",
    "                            'gpt2-xl_layer_-1_1', 'gpt2-xl_layer_-1_1', subjects_blank, shuffled=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"OASM, SHUFFLED, BLANK\")\n",
    "_, _ = compare_perf_when_using_val('blank', y_true_shuffled, \n",
    "                            test_fold_idx_shuffled, \n",
    "                            np.round(np.arange(0.1,4.8,0.1),3), \n",
    "                            mse_intercept_shuffled,\n",
    "                            'OASM-all-sigma_-1_1', 'OASM-all-sigma_-1_1', subjects_blank, shuffled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2-XL, NOT SHUFFLED, BLANK\n",
      "Performance when using val to select best layer/hparam (per-participant mean, then across participants): 0.00013014674186706543\n",
      "Performance when using test set (best layer by test R², per-participant mean, then across participants): 0.00036519853364957257\n",
      "POS, NOT SHUFFLED, BLANK\n",
      "Performance when using val to select best layer/hparam (per-participant mean, then across participants): 0.006913880538195372\n",
      "Performance when using test set (best layer by test R², per-participant mean, then across participants): 0.008489313158332183\n"
     ]
    }
   ],
   "source": [
    "results_dir = \"results_blank\"  # or any other directory you want\n",
    "shuffled = False  # set True/False here\n",
    "\n",
    "subjects_blank = np.load('/data/LLMs/data_processed/blank/dataset/subjects.npy', allow_pickle=True)\n",
    "\n",
    "# decide subfolder based on shuffled flag\n",
    "subdir = \"shuffled\" if shuffled else \"\"\n",
    "\n",
    "# add \"/\" only if needed\n",
    "folder = f\"/{subdir}\" if subdir else \"\"\n",
    "\n",
    "y_true = np.load(f\"/data/LLMs/brainscore/{results_dir}{folder}/y_test_ordered.npy\")\n",
    "test_fold_size = np.load(f\"/data/LLMs/brainscore/{results_dir}{folder}/test_fold_size.npy\")\n",
    "test_fold_idx = np.hstack(([0], np.cumsum(test_fold_size)))\n",
    "mse_intercept = np.mean(\n",
    "    np.load(f\"/data/LLMs/brainscore/{results_dir}{folder}/mse_intercept.npy\"), axis=0\n",
    ")\n",
    "\n",
    "print(f\"GPT2-XL, {'SHUFFLED' if shuffled else 'NOT SHUFFLED'}, BLANK\")\n",
    "ts_gpt, vs_gpt = compare_perf_when_using_val(\n",
    "    'blank',\n",
    "    y_true,\n",
    "    test_fold_idx,\n",
    "    np.arange(49),\n",
    "    mse_intercept,\n",
    "    'gpt2-xl_layer_-1_1',\n",
    "    'gpt2-xl_layer_-1_1',\n",
    "    subjects_blank,\n",
    "    shuffled=shuffled\n",
    ")\n",
    "\n",
    "print(f\"POS, {'SHUFFLED' if shuffled else 'NOT SHUFFLED'}, BLANK\")\n",
    "ts_gpt, vs_gpt = compare_perf_when_using_val(\n",
    "    'blank',\n",
    "    y_true,\n",
    "    test_fold_idx,\n",
    "    np.round(np.arange(3,51), 3),\n",
    "    mse_intercept,\n",
    "    'pos_layer_-1_1',\n",
    "    'pos_layer_-1_1',\n",
    "    subjects_blank,\n",
    "    shuffled=shuffled\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_brain_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
