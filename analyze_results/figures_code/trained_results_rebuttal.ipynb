{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "base = '/home3/ebrahim/what-is-brainscore/'\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "base = '/home2/ebrahim/beyond-brainscore/'\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import sys\n",
    "sys.path.append('/home2/ebrahim/beyond-brainscore/')\n",
    "from helper_funcs import find_best_layer\n",
    "from plotting_functions import plot_across_subjects, plot_test_perf_across_layers, save_fMRI_simple, pass_info_plot_hist2d, find_rows_without_nan\n",
    "from trained_results_funcs import create_pd_selected_models, find_best, max_across_selected_models\n",
    "from trained_untrained_results_funcs import max_across_nested\n",
    "from scipy.stats import pearsonr\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from scipy.stats import ttest_rel, ttest_1samp\n",
    "import nibabel as nib\n",
    "from nilearn import plotting\n",
    "from nilearn import surface\n",
    "from nilearn import datasets\n",
    "import plotly\n",
    "import brainio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/data/LLMs/data_processed/pereira/dataset/'\n",
    "llm_acts_path = '/data/LLMs/data_processed/pereira/LLM_acts/'\n",
    "results_path = '/data/LLMs/brainscore/results_pereira/trained/'\n",
    "general_res_path = '/data/LLMs/brainscore/results_pereira/'\n",
    "figurePath = '/home2/ebrahim/beyond-brainscore/analyze_results/figures_code/figures/pereira_trained_updated/'\n",
    "N = 10\n",
    "exp = ['243', '384']\n",
    "br_labels_dict = {}\n",
    "num_vox_dict = {}\n",
    "ytest_dict = {}\n",
    "mse_intercept_dict = {}\n",
    "subjects_dict = {}\n",
    "for e in exp:\n",
    "    bre = np.load(f'{data_path}networks_{e}.npy', allow_pickle=True)\n",
    "    br_labels_dict[e] = bre\n",
    "    num_vox_dict[e] = bre.shape[0]\n",
    "    mse_intercept_dict[e] = np.load(f'{general_res_path}mse_intercept_{e}.npy')\n",
    "    ytest_dict[e] = np.load(f'{general_res_path}y_test_ordered_{e}.npy')\n",
    "    subjects_dict[e] = np.load(f\"{data_path}/subjects_{e}.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'if' statement on line 9 (2335974729.py, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[24], line 11\u001b[0;36m\u001b[0m\n\u001b[0;31m    if load_pearson_model:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'if' statement on line 9\n"
     ]
    }
   ],
   "source": [
    "pearson_metric = [True, False]\n",
    "sp_str_arr = ['_lt', '_sp']\n",
    "linear_reg = [True, False]\n",
    "\n",
    "for sp_str in sp_str_arr:\n",
    "    for load_pearson_model in pearson_metric: \n",
    "        for lr in linear_reg:   \n",
    "            \n",
    "            if lr:\n",
    "                lr_str = '_noL2'\n",
    "                if sp_str == '_sp' or load_pearson_model == False:\n",
    "                    continue \n",
    "                \n",
    "            else:\n",
    "                lr_str = ''\n",
    "    \n",
    "            if load_pearson_model:\n",
    "                metric = 'r'\n",
    "                clip_zero=False\n",
    "                median=True\n",
    "                ylabel_str = \"Pearson r\"\n",
    "                yticks = [0, 0.2, 0.4]\n",
    "            else:\n",
    "                metric = 'r2'\n",
    "                clip_zero=True\n",
    "                median=False\n",
    "                ylabel_str = r'$R^2$'\n",
    "                yticks = [0, 0.05, 0.1]\n",
    "                \n",
    "            print(metric, sp_str)\n",
    "            \n",
    "            all_models_results_384 = np.load(f\"{results_path}{metric}{sp_str}_384_trained.npy\")\n",
    "            all_models_results_243 = np.load(f\"{results_path}{metric}{sp_str}_243_trained.npy\")\n",
    "            model_names = np.load(f\"{results_path}rebuttal_model_names.npy\")\n",
    "            \n",
    "            print(all_models_results_384.shape, all_models_results_243.shape)\n",
    "\n",
    "            model_name_upper = 'GPT2-XL'\n",
    "\n",
    "            SP_SL_word_vc_384 = max_across_selected_models(all_models_results_384, model_names, ['SENSE', 'SYNT', model_name_upper], '',  \n",
    "                                            num_vox_dict, br_labels_dict, subjects_dict, exp='384', updated_model_name='SP+SL+WORD')\n",
    "            SP_SL_word_LLM_vc_384 = max_across_selected_models(all_models_results_384, model_names, ['SENSE', 'SYNT'], model_name_upper,  \n",
    "                                            num_vox_dict, br_labels_dict, subjects_dict, exp='384', updated_model_name=f'SP+SL+WORD+{model_name_upper}')\n",
    "\n",
    "            SP_SL_word_vc_243 = max_across_selected_models(all_models_results_243, model_names, ['SENSE', 'SYNT', model_name_upper], '',  \n",
    "                                            num_vox_dict, br_labels_dict, subjects_dict, exp='243', updated_model_name='SP+SL+WORD')\n",
    "            SP_SL_word_LLM_vc_243 = max_across_selected_models(all_models_results_243, model_names, ['SENSE', 'SYNT'], model_name_upper,  \n",
    "                                            num_vox_dict, br_labels_dict, subjects_dict, exp='243', updated_model_name=f'SP+SL+WORD+{model_name_upper}')\n",
    "\n",
    "\n",
    "            LLM_vc_384 = max_across_selected_models(all_models_results_384, model_names, ['SP+SL', 'WORD', 'SENSE', 'SYNT'], model_name_upper,  \n",
    "                                            num_vox_dict, br_labels_dict, subjects_dict, exp='384', updated_model_name=f'{model_name_upper}')\n",
    "\n",
    "            LLM_vc_243 = max_across_selected_models(all_models_results_243, model_names, ['SP+SL', 'WORD', 'SENSE', 'SYNT'], model_name_upper,  \n",
    "                                            num_vox_dict, br_labels_dict, subjects_dict, exp='243', updated_model_name=f'{model_name_upper}')\n",
    "\n",
    "            default_palette = sns.color_palette(\"deep\")\n",
    "\n",
    "            modified_384 = pd.concat((SP_SL_word_vc_384, SP_SL_word_LLM_vc_384, LLM_vc_384))\n",
    "            modified_243 = pd.concat((SP_SL_word_vc_243, SP_SL_word_LLM_vc_243, LLM_vc_243))\n",
    "\n",
    "            _, _, _ = plot_across_subjects(modified_384.copy(), figurePath=figurePath, selected_networks=['language'],\n",
    "                                                        saveName=f\"GPT2-XL_SP+SL+WORD_{metric}{sp_str}_384\", hue_order=['SP+SL+WORD', f'SP+SL+WORD+{model_name_upper}', model_name_upper], \n",
    "                                                        yticks=yticks, order=['language'], clip_zero=clip_zero, color_palette=[default_palette[1], default_palette[9], default_palette[4]], \n",
    "                                                        draw_lines=True, ms=15, plot_legend=False, \n",
    "                                                        plot_legend_under=False, width=0.7, median=median, ylabel_str=ylabel_str)\n",
    "            _, _, _ = plot_across_subjects(modified_243.copy(), figurePath=figurePath, selected_networks=['language'],\n",
    "                                                        saveName=f\"GPT2-XL_SP+SL+WORD_{metric}{sp_str}_243\", hue_order=['SP+SL+WORD', f'SP+SL+WORD+{model_name_upper}', model_name_upper], \n",
    "                                                        yticks=yticks, order=['language'], clip_zero=clip_zero, color_palette=[default_palette[1], default_palette[9], default_palette[4]], \n",
    "                                                        draw_lines=True, ms=15, plot_legend=False, \n",
    "                                                        plot_legend_under=False, width=0.7, median=median, ylabel_str=ylabel_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_brain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
