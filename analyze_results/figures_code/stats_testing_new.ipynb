{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import wilcoxon\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['Llama', 'rwkv', 'roberta-large', 'gpt2xl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home3/ebrahim2/miniconda3/envs/llm_brain_new/lib/python3.11/site-packages/scipy/stats/_wilcoxon.py:199: UserWarning: Sample size too small for normal approximation.\n",
      "  temp = _wilcoxon_iv(x, y, zero_method, correction, alternative, method, axis)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'pereira_contig_noL2custom_': 'GPT2XL better: 0.0009765625',\n",
       " 'pereira_contig_noL2custom_-mp': 'GPT2XL better: 0.0009765625',\n",
       " 'pereira_contig_noL2custom_-sp': 'GPT2XL better: 0.0009765625',\n",
       " 'pereira_contig_': 'GPT2XL better: 0.0009765625',\n",
       " 'pereira_contig_-mp': 'GPT2XL better: 0.0009765625',\n",
       " 'pereira_contig_-sp': 'GPT2XL better: 0.0009765625',\n",
       " 'blank_contig_noL2custom_': 'GPT2XL better: 0.033944577430914495',\n",
       " 'blank_contig_noL2custom_-mp': 'GPT2XL better: 0.03125',\n",
       " 'blank_contig_noL2custom_-sp': 'GPT2XL better: 0.03125',\n",
       " 'blank_contig_': 'GPT2XL better: 0.0625',\n",
       " 'blank_contig_-mp': 'GPT2XL better: 0.0625',\n",
       " 'blank_contig_-sp': 'GPT2XL better: 0.0625',\n",
       " 'fedorenko_contig_noL2custom_': 'GPT2XL better: 0.03125',\n",
       " 'fedorenko_contig_noL2custom_-mp': 'GPT2XL better: 0.03125',\n",
       " 'fedorenko_contig_noL2custom_-sp': 'GPT2XL better: 0.03125',\n",
       " 'fedorenko_contig_': 'GPT2XL better: 0.03125',\n",
       " 'fedorenko_contig_-mp': 'GPT2XL better: 0.03125',\n",
       " 'fedorenko_contig_-sp': 'GPT2XL better: 0.03125'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_pvalues = {}\n",
    "for dataset in ['pereira', 'blank', 'fedorenko']:\n",
    "    for shuffle_str in ['shuffled', 'contig']:\n",
    "        for noL2_str in ['_noL2custom', '']:\n",
    "            results = pd.read_csv(f'/home3/ebrahim2/beyond-brainscore/analyze_results/figures_code/figures_data/figure1/{dataset}_pearson_r{noL2_str}_{shuffle_str}.csv')\n",
    "            for fe in ['', '-mp', '-sp']:\n",
    "                results_gpt2xl = results.loc[results.Model==f'GPT2-XL{fe}']['perf'].to_numpy()\n",
    "                results_oasm = results.loc[results.Model=='OASM']['perf'].to_numpy()\n",
    "                result = wilcoxon(results_gpt2xl, results_oasm, alternative='greater')\n",
    "                if np.mean(results_oasm) > np.mean(results_gpt2xl):\n",
    "                    pass\n",
    "                else:\n",
    "                    store_pvalues[f\"{dataset}_{shuffle_str}{noL2_str}_{fe}\"] = f\"GPT2XL better: {result.pvalue}\"\n",
    "store_pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home3/ebrahim2/miniconda3/envs/llm_brain/lib/python3.11/site-packages/scipy/stats/_wilcoxon.py:199: UserWarning: Sample size too small for normal approximation.\n",
      "  temp = _wilcoxon_iv(x, y, zero_method, correction, alternative, method, axis)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'pereira_contig_noL2custom_': 'GPT2XL better: 0.0009765625',\n",
       " 'pereira_contig_noL2custom_-mp': 'GPT2XL better: 0.0009765625',\n",
       " 'pereira_contig_noL2custom_-sp': 'GPT2XL better: 0.0009765625',\n",
       " 'pereira_contig_': 'GPT2XL better: 0.0009765625',\n",
       " 'pereira_contig_-mp': 'GPT2XL better: 0.0009765625',\n",
       " 'pereira_contig_-sp': 'GPT2XL better: 0.0009765625',\n",
       " 'blank_contig_noL2custom_': 'GPT2XL better: 0.033944577430914495',\n",
       " 'blank_contig_noL2custom_-mp': 'GPT2XL better: 0.03125',\n",
       " 'blank_contig_noL2custom_-sp': 'GPT2XL better: 0.03125',\n",
       " 'blank_contig_': 'GPT2XL better: 0.0625',\n",
       " 'blank_contig_-mp': 'GPT2XL better: 0.0625',\n",
       " 'blank_contig_-sp': 'GPT2XL better: 0.0625',\n",
       " 'fedorenko_contig_noL2custom_': 'GPT2XL better: 0.03125',\n",
       " 'fedorenko_contig_noL2custom_-mp': 'GPT2XL better: 0.03125',\n",
       " 'fedorenko_contig_noL2custom_-sp': 'GPT2XL better: 0.03125',\n",
       " 'fedorenko_contig_': 'GPT2XL better: 0.03125',\n",
       " 'fedorenko_contig_-mp': 'GPT2XL better: 0.03125',\n",
       " 'fedorenko_contig_-sp': 'GPT2XL better: 0.03125'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_pvalues = {}\n",
    "for dataset in ['pereira', 'blank', 'fedorenko']:\n",
    "    for shuffle_str in ['shuffled', 'contig']:\n",
    "        for noL2_str in ['_noL2custom', '']:\n",
    "            results = pd.read_csv(f'/home3/ebrahim2/beyond-brainscore/analyze_results/figures_code/figures_data/figure1/{dataset}_pearson_r{noL2_str}_{shuffle_str}.csv')\n",
    "            for fe in ['', '-mp', '-sp']:\n",
    "                results_gpt2xl = results.loc[results.Model==f'GPT2-XL{fe}']['perf'].to_numpy()\n",
    "                results_oasm = results.loc[results.Model=='OASM']['perf'].to_numpy()\n",
    "                result = wilcoxon(results_gpt2xl, results_oasm, alternative='greater')\n",
    "                if np.mean(results_oasm) > np.mean(results_gpt2xl):\n",
    "                    pass\n",
    "                else:\n",
    "                    store_pvalues[f\"{dataset}_{shuffle_str}{noL2_str}_{fe}\"] = f\"GPT2XL better: {result.pvalue}\"\n",
    "store_pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pereira_-lt': 'GPT2XL better: 0.0029296875',\n",
       " 'pereira_-mp': 'GPT2XL better: 0.052734375',\n",
       " 'pereira_-sp': 'GPT2XL better: 0.013671875',\n",
       " 'blank_-lt': 'Simple better: 1.0',\n",
       " 'blank_-mp': 'Simple better: 1.0',\n",
       " 'blank_-sp': 'Simple better: 1.0',\n",
       " 'fedorenko_-lt': 'GPT2XL better: 0.59375',\n",
       " 'fedorenko_-mp': 'GPT2XL better: 0.5',\n",
       " 'fedorenko_-sp': 'GPT2XL better: 0.3125'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_pvalues = {}\n",
    "for dataset in ['pereira', 'blank', 'fedorenko']:\n",
    "    for fe in ['-lt', '-mp', '-sp']:\n",
    "        results = pd.read_csv(f'/home3/ebrahim2/beyond-brainscore/analyze_results/figures_code/figures_data/figure4/{dataset}_pearson_r.csv')\n",
    "        results_gpt2xl = results.loc[results.Model==f'GPT2XL{fe}']['perf'].to_numpy()\n",
    "        results_simple = results.loc[results.Model=='Simple']['perf'].to_numpy()\n",
    "        result = wilcoxon(results_gpt2xl, results_simple, alternative='greater')\n",
    "        \n",
    "                    \n",
    "        if np.mean(results_simple) > np.mean(results_gpt2xl):\n",
    "            store_pvalues[f\"{dataset}_{fe}\"] = f\"Simple better: {result.pvalue}\"\n",
    "        else:\n",
    "            store_pvalues[f\"{dataset}_{fe}\"] = f\"GPT2XL better: {result.pvalue}\"\n",
    "            \n",
    "store_pvalues\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pereira_-lt': 'Simple better: 1.0',\n",
       " 'pereira_-mp': 'Simple better: 0.9755859375',\n",
       " 'pereira_-sp': 'Simple better: 0.9345703125',\n",
       " 'blank_-lt': 'Simple better: 1.0',\n",
       " 'blank_-mp': 'Simple better: 0.96875',\n",
       " 'blank_-sp': 'Simple better: 1.0',\n",
       " 'fedorenko_-lt': 'Simple better: 0.90625',\n",
       " 'fedorenko_-mp': 'Simple better: 0.84375',\n",
       " 'fedorenko_-sp': 'Simple better: 0.90625'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_pvalues = {}\n",
    "for dataset in ['pereira', 'blank', 'fedorenko']:\n",
    "    for fe in ['-lt', '-mp', '-sp']:\n",
    "        results = pd.read_csv(f'/home3/ebrahim2/beyond-brainscore/analyze_results/figures_code/figures_data/figure5/{dataset}_pearson_r.csv')\n",
    "        results_gpt2xl = results.loc[results.Model==f'GPT2XLU{fe}']['perf'].to_numpy()\n",
    "        results_simple = results.loc[results.Model=='Simple']['perf'].to_numpy()\n",
    "        result = wilcoxon(results_gpt2xl, results_simple, alternative='greater')\n",
    "        \n",
    "        if np.mean(results_simple) > np.mean(results_gpt2xl):\n",
    "            store_pvalues[f\"{dataset}_{fe}\"] = f\"Simple better: {result.pvalue}\"\n",
    "        else:\n",
    "            store_pvalues[f\"{dataset}_{fe}\"] = f\"GPT2XL better: {result.pvalue}\"\n",
    "            \n",
    "store_pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_palette = sns.color_palette([\"gray\", \"blue\", 'black'])\n",
    "def compute_frac_sig(feature_extraction_arr, dataset, figure_folder, llm_name='', ymax=30, chunked=False):\n",
    "    \n",
    "    if len(llm_name) > 0:\n",
    "        llm_name = f\"_{llm_name}\"\n",
    "        \n",
    "    if chunked:\n",
    "        df_name = 'blocked_pvalues'\n",
    "    else:\n",
    "        df_name = 'pvalues'\n",
    "    \n",
    "    df = pd.read_csv(f'/home3/ebrahim2/beyond-brainscore/analyze_results/figures_code/figures_data/{figure_folder}/{df_name}_{dataset}{llm_name}.csv')\n",
    "    fig, ax = plt.subplots(1,1,figsize=(3,4))\n",
    "    plot_stats_df = {'values': [], 'feature_extraction_arr': [], 'dataset': []}\n",
    "    \n",
    "    for fe in feature_extraction_arr: \n",
    "        \n",
    "        df_fe = df.loc[df.fe==fe].copy()\n",
    "        print(df_fe.shape, dataset)\n",
    "        df_fe['pval_sig'] = np.where(df_fe['pval']<0.05, 1, 0)\n",
    "\n",
    "        df_fe['pval_LLM_sig'] = np.where(df_fe['pval_LLM_sig']<0.05, 1, 0)\n",
    "  \n",
    "        #df_fe = df_fe.loc[df_fe[f'pval_LLM_sig'] == 1]\n",
    "\n",
    "        if df_fe.shape[0] == 0:\n",
    "            print(f\"No significant voxels/electrodes/fROIs for {llm_name}{fe} for {dataset}\")\n",
    "    \n",
    "        # Calculate the mean proportion of significant p-values per subject\n",
    "        subject_means = df_fe.groupby('subject')['pval_sig'].mean()\n",
    "\n",
    "        plot_stats_df['values'].extend(np.array(subject_means)*100)\n",
    "        plot_stats_df['feature_extraction_arr'].extend(np.repeat(fe, len(subject_means)))\n",
    "        plot_stats_df['dataset'].extend(np.repeat(dataset, len(subject_means)))\n",
    "        \n",
    "        print(np.mean(subject_means))\n",
    "        \n",
    "        \n",
    "    plot_stats_df = pd.DataFrame(plot_stats_df)\n",
    "    sns.barplot(plot_stats_df, hue='feature_extraction_arr', y='values', x='dataset', alpha=0.4, legend=False, errorbar=None, palette=color_palette,ax=ax)\n",
    "    sns.stripplot(plot_stats_df, hue='feature_extraction_arr', y='values', x='dataset', dodge=True, size=10, alpha=0.8, legend=False, palette=color_palette,ax=ax)\n",
    "    sns.despine()\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_xticklabels('')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([0,ymax])\n",
    "    ax.set_yticklabels([0,ymax], fontsize=20)\n",
    "    ax.set_ylabel('')\n",
    "    \n",
    "    if chunked:\n",
    "        fig.savefig(f'/home3/ebrahim2/beyond-brainscore/analyze_results/figures_code/figures/new_figures/{figure_folder}/sig/chunked_frac_sig_{dataset}_{llm_name}.png', bbox_inches='tight')\n",
    "        fig.savefig(f'/home3/ebrahim2/beyond-brainscore/analyze_results/figures_code/figures/new_figures/{figure_folder}/sig/chunked_frac_sig_{dataset}_{llm_name}.pdf', bbox_inches='tight')   \n",
    "    else:\n",
    "        fig.savefig(f'/home3/ebrahim2/beyond-brainscore/analyze_results/figures_code/figures/new_figures/{figure_folder}/sig/frac_sig_{dataset}_{llm_name}.png', bbox_inches='tight')\n",
    "        fig.savefig(f'/home3/ebrahim2/beyond-brainscore/analyze_results/figures_code/figures/new_figures/{figure_folder}/sig/frac_sig_{dataset}_{llm_name}.pdf', bbox_inches='tight')   \n",
    "        \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13553, 8) pereira\n",
      "0.22026116324437695\n",
      "(13553, 8) pereira\n",
      "0.18504614886382037\n",
      "(13553, 8) pereira\n",
      "0.2336163474787043\n",
      "(97, 8) fedorenko\n",
      "0.2938416075650118\n",
      "(97, 8) fedorenko\n",
      "0.28807328605200944\n",
      "(97, 8) fedorenko\n",
      "0.22160756501182033\n",
      "(60, 8) blank\n",
      "0.0\n",
      "(60, 8) blank\n",
      "0.0\n",
      "(60, 8) blank\n",
      "0.016666666666666666\n"
     ]
    }
   ],
   "source": [
    "compute_frac_sig(['-lt', '-mp', '-sp'], 'pereira', 'figure2', chunked=True)\n",
    "compute_frac_sig(['-lt', '-mp', '-sp'], 'fedorenko', 'figure2', chunked=True)\n",
    "compute_frac_sig(['-lt', '-mp', '-sp'], 'blank', 'figure2', chunked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13553, 8) pereira\n",
      "0.22026116324437695\n",
      "(13553, 8) pereira\n",
      "0.18504614886382037\n",
      "(13553, 8) pereira\n",
      "0.2336163474787043\n",
      "(97, 8) fedorenko\n",
      "0.2938416075650118\n",
      "(97, 8) fedorenko\n",
      "0.28807328605200944\n",
      "(97, 8) fedorenko\n",
      "0.22160756501182033\n",
      "(60, 8) blank\n",
      "0.0\n",
      "(60, 8) blank\n",
      "0.0\n",
      "(60, 8) blank\n",
      "0.016666666666666666\n"
     ]
    }
   ],
   "source": [
    "compute_frac_sig(['-lt', '-mp', '-sp'], 'pereira','figure2')\n",
    "compute_frac_sig(['-lt', '-mp', '-sp'], 'fedorenko','figure2')\n",
    "compute_frac_sig(['-lt', '-mp', '-sp'], 'blank','figure2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13553, 8) pereira\n",
      "0.000662739322533137\n",
      "(13553, 8) pereira\n",
      "0.07619034767790638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4052165/3388948640.py:37: UserWarning: The palette list has more values (3) than needed (1), which may not be intended.\n",
      "  sns.barplot(plot_stats_df, hue='feature_extraction_arr', y='values', x='dataset', alpha=0.4, legend=False, errorbar=None, palette=color_palette,ax=ax)\n",
      "/tmp/ipykernel_4052165/3388948640.py:38: UserWarning: The palette list has more values (3) than needed (1), which may not be intended.\n",
      "  sns.stripplot(plot_stats_df, hue='feature_extraction_arr', y='values', x='dataset', dodge=True, size=10, alpha=0.8, legend=False, palette=color_palette,ax=ax)\n",
      "/tmp/ipykernel_4052165/3388948640.py:37: UserWarning: The palette list has more values (3) than needed (1), which may not be intended.\n",
      "  sns.barplot(plot_stats_df, hue='feature_extraction_arr', y='values', x='dataset', alpha=0.4, legend=False, errorbar=None, palette=color_palette,ax=ax)\n",
      "/tmp/ipykernel_4052165/3388948640.py:38: UserWarning: The palette list has more values (3) than needed (1), which may not be intended.\n",
      "  sns.stripplot(plot_stats_df, hue='feature_extraction_arr', y='values', x='dataset', dodge=True, size=10, alpha=0.8, legend=False, palette=color_palette,ax=ax)\n"
     ]
    }
   ],
   "source": [
    "compute_frac_sig(['-lt'], 'pereira','synt', 'syntax', ymax=50)\n",
    "compute_frac_sig(['-lt'], 'pereira','glove', 'glove', ymax=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Llama', 'rwkv', 'roberta-large', 'gpt2xl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llama\n",
      "(13553, 8) pereira\n",
      "0.007511045655375552\n",
      "(13553, 8) pereira\n",
      "0.024374079528718704\n",
      "(13553, 8) pereira\n",
      "0.0529501345526606\n",
      "(97, 8) fedorenko\n",
      "0.03333333333333333\n",
      "(97, 8) fedorenko\n",
      "0.06\n",
      "(97, 8) fedorenko\n",
      "0.04666666666666666\n",
      "(60, 8) blank\n",
      "0.0\n",
      "(60, 8) blank\n",
      "0.0\n",
      "(60, 8) blank\n",
      "0.0\n",
      "rwkv\n",
      "(13553, 8) pereira\n",
      "0.005522827687776141\n",
      "(13553, 8) pereira\n",
      "0.002430370977159241\n",
      "(13553, 8) pereira\n",
      "0.0246790398568884\n",
      "(97, 8) fedorenko\n",
      "0.024444444444444442\n",
      "(97, 8) fedorenko\n",
      "0.04666666666666666\n",
      "(97, 8) fedorenko\n",
      "0.06888888888888889\n",
      "(60, 8) blank\n",
      "0.0\n",
      "(60, 8) blank\n",
      "0.0\n",
      "(60, 8) blank\n",
      "0.0\n",
      "roberta-large\n",
      "(13553, 8) pereira\n",
      "7.363770250368188e-05\n",
      "(13553, 8) pereira\n",
      "0.04657064207450131\n",
      "(13553, 8) pereira\n",
      "0.04194303294805265\n",
      "(97, 8) fedorenko\n",
      "0.0\n",
      "(97, 8) fedorenko\n",
      "0.04666666666666666\n",
      "(97, 8) fedorenko\n",
      "0.057777777777777775\n",
      "(60, 8) blank\n",
      "0.0\n",
      "(60, 8) blank\n",
      "0.0\n",
      "(60, 8) blank\n",
      "0.0\n",
      "gpt2xl\n",
      "(13553, 8) pereira\n",
      "0.000589101620029455\n",
      "(13553, 8) pereira\n",
      "0.014311310339560169\n",
      "(13553, 8) pereira\n",
      "0.03411199099383911\n",
      "(97, 8) fedorenko\n",
      "0.04666666666666666\n",
      "(97, 8) fedorenko\n",
      "0.04666666666666666\n",
      "(97, 8) fedorenko\n",
      "0.04666666666666666\n",
      "(60, 8) blank\n",
      "0.0\n",
      "(60, 8) blank\n",
      "0.0\n",
      "(60, 8) blank\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "for model in model_names:\n",
    "    print(model)\n",
    "    compute_frac_sig(['-lt', '-mp', '-sp'], 'pereira', 'figure4', model)\n",
    "    compute_frac_sig(['-lt', '-mp', '-sp'], 'fedorenko', 'figure4', model)\n",
    "    compute_frac_sig(['-lt', '-mp', '-sp'], 'blank', 'figure4', model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for model in \n",
    "compute_frac_sig(['-lt', '-mp', '-sp'], 'pereira', 4, 'gpt2xl')\n",
    "compute_frac_sig(['-lt', '-mp', '-sp'], 'fedorenko', 4, 'gpt2xl')\n",
    "compute_frac_sig(['-lt', '-mp', '-sp'], 'blank', 4, 'gpt2xl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llama\n",
      "(13553, 8) pereira\n",
      "0.007511045655375552\n",
      "(13553, 8) pereira\n",
      "0.024374079528718704\n",
      "(13553, 8) pereira\n",
      "0.0529501345526606\n",
      "(97, 8) fedorenko\n",
      "0.03333333333333333\n",
      "(97, 8) fedorenko\n",
      "0.06\n",
      "(97, 8) fedorenko\n",
      "0.04666666666666666\n",
      "(60, 8) blank\n",
      "0.0\n",
      "(60, 8) blank\n",
      "0.0\n",
      "(60, 8) blank\n",
      "0.0\n",
      "rwkv\n",
      "(13553, 8) pereira\n",
      "0.005522827687776141\n",
      "(13553, 8) pereira\n",
      "0.002430370977159241\n",
      "(13553, 8) pereira\n",
      "0.0246790398568884\n",
      "(97, 8) fedorenko\n",
      "0.024444444444444442\n",
      "(97, 8) fedorenko\n",
      "0.04666666666666666\n",
      "(97, 8) fedorenko\n",
      "0.06888888888888889\n",
      "(60, 8) blank\n",
      "0.0\n",
      "(60, 8) blank\n",
      "0.0\n",
      "(60, 8) blank\n",
      "0.0\n",
      "roberta-large\n",
      "(13553, 8) pereira\n",
      "7.363770250368188e-05\n",
      "(13553, 8) pereira\n",
      "0.04657064207450131\n",
      "(13553, 8) pereira\n",
      "0.04194303294805265\n",
      "(97, 8) fedorenko\n",
      "0.0\n",
      "(97, 8) fedorenko\n",
      "0.04666666666666666\n",
      "(97, 8) fedorenko\n",
      "0.057777777777777775\n",
      "(60, 8) blank\n",
      "0.0\n",
      "(60, 8) blank\n",
      "0.0\n",
      "(60, 8) blank\n",
      "0.0\n",
      "gpt2xl\n",
      "(13553, 8) pereira\n",
      "0.000589101620029455\n",
      "(13553, 8) pereira\n",
      "0.014311310339560169\n",
      "(13553, 8) pereira\n",
      "0.03411199099383911\n",
      "(97, 8) fedorenko\n",
      "0.04666666666666666\n",
      "(97, 8) fedorenko\n",
      "0.04666666666666666\n",
      "(97, 8) fedorenko\n",
      "0.04666666666666666\n",
      "(60, 8) blank\n",
      "0.0\n",
      "(60, 8) blank\n",
      "0.0\n",
      "(60, 8) blank\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "for model in model_names:\n",
    "    print(model)\n",
    "    compute_frac_sig(['-lt', '-mp', '-sp'], 'pereira', 'figure4', model)\n",
    "    compute_frac_sig(['-lt', '-mp', '-sp'], 'fedorenko', 'figure4', model)\n",
    "    compute_frac_sig(['-lt', '-mp', '-sp'], 'blank', 'figure4', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13553, 8) pereira\n",
      "0.0\n",
      "(13553, 8) pereira\n",
      "0.0\n",
      "(13553, 8) pereira\n",
      "0.0\n",
      "(97, 8) fedorenko\n",
      "0.0\n",
      "(97, 8) fedorenko\n",
      "0.0\n",
      "(97, 8) fedorenko\n",
      "0.0\n",
      "(60, 8) blank\n",
      "0.0\n",
      "(60, 8) blank\n",
      "0.0\n",
      "(60, 8) blank\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "compute_frac_sig(['-lt', '-mp', '-sp'], 'pereira','figure5')\n",
    "compute_frac_sig(['-lt', '-mp', '-sp'], 'fedorenko','figure5')\n",
    "compute_frac_sig(['-lt', '-mp', '-sp'], 'blank','figure5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_brain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
