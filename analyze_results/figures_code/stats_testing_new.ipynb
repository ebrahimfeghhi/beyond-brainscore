{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import wilcoxon\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['Llama', 'rwkv', 'roberta-large', 'gpt2xl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home3/ebrahim2/miniconda3/envs/llm_brain_new/lib/python3.11/site-packages/scipy/stats/_wilcoxon.py:199: UserWarning: Sample size too small for normal approximation.\n",
      "  temp = _wilcoxon_iv(x, y, zero_method, correction, alternative, method, axis)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'pereira_contig_noL2custom_': 'GPT2XL better: 0.0009765625',\n",
       " 'pereira_contig_noL2custom_-mp': 'GPT2XL better: 0.0009765625',\n",
       " 'pereira_contig_noL2custom_-sp': 'GPT2XL better: 0.0009765625',\n",
       " 'pereira_contig_': 'GPT2XL better: 0.0009765625',\n",
       " 'pereira_contig_-mp': 'GPT2XL better: 0.0009765625',\n",
       " 'pereira_contig_-sp': 'GPT2XL better: 0.0009765625',\n",
       " 'blank_contig_noL2custom_': 'GPT2XL better: 0.033944577430914495',\n",
       " 'blank_contig_noL2custom_-mp': 'GPT2XL better: 0.03125',\n",
       " 'blank_contig_noL2custom_-sp': 'GPT2XL better: 0.03125',\n",
       " 'blank_contig_': 'GPT2XL better: 0.0625',\n",
       " 'blank_contig_-mp': 'GPT2XL better: 0.0625',\n",
       " 'blank_contig_-sp': 'GPT2XL better: 0.0625',\n",
       " 'fedorenko_contig_noL2custom_': 'GPT2XL better: 0.03125',\n",
       " 'fedorenko_contig_noL2custom_-mp': 'GPT2XL better: 0.03125',\n",
       " 'fedorenko_contig_noL2custom_-sp': 'GPT2XL better: 0.03125',\n",
       " 'fedorenko_contig_': 'GPT2XL better: 0.03125',\n",
       " 'fedorenko_contig_-mp': 'GPT2XL better: 0.03125',\n",
       " 'fedorenko_contig_-sp': 'GPT2XL better: 0.03125'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_pvalues = {}\n",
    "for dataset in ['pereira', 'blank', 'fedorenko']:\n",
    "    for shuffle_str in ['shuffled', 'contig']:\n",
    "        for noL2_str in ['_noL2custom', '']:\n",
    "            results = pd.read_csv(f'/home3/ebrahim2/beyond-brainscore/analyze_results/figures_code/figures_data/figure1/{dataset}_pearson_r{noL2_str}_{shuffle_str}.csv')\n",
    "            for fe in ['', '-mp', '-sp']:\n",
    "                results_gpt2xl = results.loc[results.Model==f'GPT2-XL{fe}']['perf'].to_numpy()\n",
    "                results_oasm = results.loc[results.Model=='OASM']['perf'].to_numpy()\n",
    "                result = wilcoxon(results_gpt2xl, results_oasm, alternative='greater')\n",
    "                if np.mean(results_oasm) > np.mean(results_gpt2xl):\n",
    "                    pass\n",
    "                else:\n",
    "                    store_pvalues[f\"{dataset}_{shuffle_str}{noL2_str}_{fe}\"] = f\"GPT2XL better: {result.pvalue}\"\n",
    "store_pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home3/ebrahim2/miniconda3/envs/llm_brain/lib/python3.11/site-packages/scipy/stats/_wilcoxon.py:199: UserWarning: Sample size too small for normal approximation.\n",
      "  temp = _wilcoxon_iv(x, y, zero_method, correction, alternative, method, axis)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'pereira_contig_noL2custom_': 'GPT2XL better: 0.0009765625',\n",
       " 'pereira_contig_noL2custom_-mp': 'GPT2XL better: 0.0009765625',\n",
       " 'pereira_contig_noL2custom_-sp': 'GPT2XL better: 0.0009765625',\n",
       " 'pereira_contig_': 'GPT2XL better: 0.0009765625',\n",
       " 'pereira_contig_-mp': 'GPT2XL better: 0.0009765625',\n",
       " 'pereira_contig_-sp': 'GPT2XL better: 0.0009765625',\n",
       " 'blank_contig_noL2custom_': 'GPT2XL better: 0.033944577430914495',\n",
       " 'blank_contig_noL2custom_-mp': 'GPT2XL better: 0.03125',\n",
       " 'blank_contig_noL2custom_-sp': 'GPT2XL better: 0.03125',\n",
       " 'blank_contig_': 'GPT2XL better: 0.0625',\n",
       " 'blank_contig_-mp': 'GPT2XL better: 0.0625',\n",
       " 'blank_contig_-sp': 'GPT2XL better: 0.0625',\n",
       " 'fedorenko_contig_noL2custom_': 'GPT2XL better: 0.03125',\n",
       " 'fedorenko_contig_noL2custom_-mp': 'GPT2XL better: 0.03125',\n",
       " 'fedorenko_contig_noL2custom_-sp': 'GPT2XL better: 0.03125',\n",
       " 'fedorenko_contig_': 'GPT2XL better: 0.03125',\n",
       " 'fedorenko_contig_-mp': 'GPT2XL better: 0.03125',\n",
       " 'fedorenko_contig_-sp': 'GPT2XL better: 0.03125'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_pvalues = {}\n",
    "for dataset in ['pereira', 'blank', 'fedorenko']:\n",
    "    for shuffle_str in ['shuffled', 'contig']:\n",
    "        for noL2_str in ['_noL2custom', '']:\n",
    "            results = pd.read_csv(f'/home3/ebrahim2/beyond-brainscore/analyze_results/figures_code/figures_data/figure1/{dataset}_pearson_r{noL2_str}_{shuffle_str}.csv')\n",
    "            for fe in ['', '-mp', '-sp']:\n",
    "                results_gpt2xl = results.loc[results.Model==f'GPT2-XL{fe}']['perf'].to_numpy()\n",
    "                results_oasm = results.loc[results.Model=='OASM']['perf'].to_numpy()\n",
    "                result = wilcoxon(results_gpt2xl, results_oasm, alternative='greater')\n",
    "                if np.mean(results_oasm) > np.mean(results_gpt2xl):\n",
    "                    pass\n",
    "                else:\n",
    "                    store_pvalues[f\"{dataset}_{shuffle_str}{noL2_str}_{fe}\"] = f\"GPT2XL better: {result.pvalue}\"\n",
    "store_pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pereira_-lt': 'GPT2XL better: 0.001953125',\n",
       " 'pereira_-mp': 'GPT2XL better: 0.052734375',\n",
       " 'pereira_-sp': 'GPT2XL better: 0.009765625',\n",
       " 'blank_-lt': 'Simple better: 1.0',\n",
       " 'blank_-mp': 'Simple better: 1.0',\n",
       " 'blank_-sp': 'Simple better: 1.0',\n",
       " 'fedorenko_-lt': 'GPT2XL better: 0.59375',\n",
       " 'fedorenko_-mp': 'GPT2XL better: 0.5',\n",
       " 'fedorenko_-sp': 'GPT2XL better: 0.3125'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_pvalues = {}\n",
    "for dataset in ['pereira', 'blank', 'fedorenko']:\n",
    "    for fe in ['-lt', '-mp', '-sp']:\n",
    "        results = pd.read_csv(f'/home3/ebrahim2/beyond-brainscore/analyze_results/figures_code/figures_data/figure4/{dataset}_pearson_r_gpt2xl.csv')\n",
    "        results_gpt2xl = results.loc[results.Model==f'gpt2xl{fe}']['perf'].to_numpy()\n",
    "        results_simple = results.loc[results.Model=='Simple']['perf'].to_numpy()\n",
    "        result = wilcoxon(results_gpt2xl, results_simple, alternative='greater')\n",
    "        \n",
    "        if np.mean(results_simple) > np.mean(results_gpt2xl):\n",
    "            store_pvalues[f\"{dataset}_{fe}\"] = f\"Simple better: {result.pvalue}\"\n",
    "        else:\n",
    "            store_pvalues[f\"{dataset}_{fe}\"] = f\"GPT2XL better: {result.pvalue}\"\n",
    "            \n",
    "store_pvalues\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pereira_-lt': 'Simple better: 1.0',\n",
       " 'pereira_-mp': 'Simple better: 0.9755859375',\n",
       " 'pereira_-sp': 'Simple better: 0.9345703125',\n",
       " 'blank_-lt': 'Simple better: 1.0',\n",
       " 'blank_-mp': 'Simple better: 0.96875',\n",
       " 'blank_-sp': 'Simple better: 1.0',\n",
       " 'fedorenko_-lt': 'Simple better: 0.90625',\n",
       " 'fedorenko_-mp': 'Simple better: 0.84375',\n",
       " 'fedorenko_-sp': 'Simple better: 0.90625'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_pvalues = {}\n",
    "for dataset in ['pereira', 'blank', 'fedorenko']:\n",
    "    for fe in ['-lt', '-mp', '-sp']:\n",
    "        results = pd.read_csv(f'/home3/ebrahim2/beyond-brainscore/analyze_results/figures_code/figures_data/figure5/{dataset}_pearson_r.csv')\n",
    "        results_gpt2xl = results.loc[results.Model==f'GPT2XLU{fe}']['perf'].to_numpy()\n",
    "        results_simple = results.loc[results.Model=='Simple']['perf'].to_numpy()\n",
    "        result = wilcoxon(results_gpt2xl, results_simple, alternative='greater')\n",
    "        \n",
    "        if np.mean(results_simple) > np.mean(results_gpt2xl):\n",
    "            store_pvalues[f\"{dataset}_{fe}\"] = f\"Simple better: {result.pvalue}\"\n",
    "        else:\n",
    "            store_pvalues[f\"{dataset}_{fe}\"] = f\"GPT2XL better: {result.pvalue}\"\n",
    "            \n",
    "store_pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_palette = sns.color_palette([\"gray\", \"blue\", 'black'])\n",
    "def compute_frac_sig(feature_extraction_arr, dataset, figure_folder, llm_name='', ymax=30, chunked=False):\n",
    "    \n",
    "    if len(llm_name) > 0:\n",
    "        llm_name = f\"_{llm_name}\"\n",
    "        \n",
    "    if chunked:\n",
    "        df_name = 'blocked_pvalues'\n",
    "    else:\n",
    "        df_name = 'pvalues'\n",
    "    \n",
    "    df = pd.read_csv(f'/home3/ebrahim2/beyond-brainscore/analyze_results/figures_code/figures_data/{figure_folder}/{df_name}_{dataset}{llm_name}.csv')\n",
    "    fig, ax = plt.subplots(1,1,figsize=(3,4))\n",
    "    plot_stats_df = {'values': [], 'feature_extraction_arr': [], 'dataset': []}\n",
    "    \n",
    "    for fe in feature_extraction_arr: \n",
    "        \n",
    "        df_fe = df.loc[df.fe==fe].copy()\n",
    "        print(df_fe.shape, dataset)\n",
    "        df_fe['pval_sig'] = np.where(df_fe['pval']<0.05, 1, 0)\n",
    "\n",
    "        df_fe['pval_LLM_sig'] = np.where(df_fe['pval_LLM_sig']<0.05, 1, 0)\n",
    "  \n",
    "        #df_fe = df_fe.loc[df_fe[f'pval_LLM_sig'] == 1]\n",
    "\n",
    "        if df_fe.shape[0] == 0:\n",
    "            print(f\"No significant voxels/electrodes/fROIs for {llm_name}{fe} for {dataset}\")\n",
    "    \n",
    "        # Calculate the mean proportion of significant p-values per subject\n",
    "        subject_means = df_fe.groupby('subject')['pval_sig'].mean()\n",
    "\n",
    "        plot_stats_df['values'].extend(np.array(subject_means)*100)\n",
    "        plot_stats_df['feature_extraction_arr'].extend(np.repeat(fe, len(subject_means)))\n",
    "        plot_stats_df['dataset'].extend(np.repeat(dataset, len(subject_means)))\n",
    "        \n",
    "        print(np.mean(subject_means))\n",
    "        \n",
    "        \n",
    "    plot_stats_df = pd.DataFrame(plot_stats_df)\n",
    "    sns.barplot(plot_stats_df, hue='feature_extraction_arr', y='values', x='dataset', alpha=0.4, legend=False, errorbar=None, palette=color_palette,ax=ax)\n",
    "    sns.stripplot(plot_stats_df, hue='feature_extraction_arr', y='values', x='dataset', dodge=True, size=10, alpha=0.8, legend=False, palette=color_palette,ax=ax)\n",
    "    sns.despine()\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_xticklabels('')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([0,ymax])\n",
    "    ax.set_yticklabels([0,ymax], fontsize=20)\n",
    "    ax.set_ylabel('')\n",
    "    \n",
    "    if chunked:\n",
    "        print(\"Saving chunked\")\n",
    "        fig.savefig(f'/home3/ebrahim2/beyond-brainscore/analyze_results/figures_code/figures/new_figures/{figure_folder}/sig/chunked_frac_sig_{dataset}_{llm_name}.png', bbox_inches='tight')\n",
    "        fig.savefig(f'/home3/ebrahim2/beyond-brainscore/analyze_results/figures_code/figures/new_figures/{figure_folder}/sig/chunked_frac_sig_{dataset}_{llm_name}.pdf', bbox_inches='tight')   \n",
    "    else:\n",
    "        fig.savefig(f'/home3/ebrahim2/beyond-brainscore/analyze_results/figures_code/figures/new_figures/{figure_folder}/sig/frac_sig_{dataset}_{llm_name}.png', bbox_inches='tight')\n",
    "        fig.savefig(f'/home3/ebrahim2/beyond-brainscore/analyze_results/figures_code/figures/new_figures/{figure_folder}/sig/frac_sig_{dataset}_{llm_name}.pdf', bbox_inches='tight')   \n",
    "        \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13553, 8) pereira\n",
      "0.20226464850527032\n",
      "(13553, 8) pereira\n",
      "0.1672370054515032\n",
      "(13553, 8) pereira\n",
      "0.22631811863894144\n",
      "Saving chunked\n",
      "(97, 8) fedorenko\n",
      "0.2136643026004728\n",
      "(97, 8) fedorenko\n",
      "0.28381796690307326\n",
      "(97, 8) fedorenko\n",
      "0.19347517730496452\n",
      "Saving chunked\n",
      "(60, 8) blank\n",
      "0.0\n",
      "(60, 8) blank\n",
      "0.0\n",
      "(60, 8) blank\n",
      "0.016666666666666666\n",
      "Saving chunked\n"
     ]
    }
   ],
   "source": [
    "compute_frac_sig(['-lt', '-mp', '-sp'], 'pereira', 'figure2', chunked=True)\n",
    "compute_frac_sig(['-lt', '-mp', '-sp'], 'fedorenko', 'figure2', chunked=True)\n",
    "compute_frac_sig(['-lt', '-mp', '-sp'], 'blank', 'figure2', chunked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13553, 8) pereira\n",
      "0.22026116324437695\n",
      "(13553, 8) pereira\n",
      "0.18504614886382037\n",
      "(13553, 8) pereira\n",
      "0.2336163474787043\n",
      "(97, 8) fedorenko\n",
      "0.2938416075650118\n",
      "(97, 8) fedorenko\n",
      "0.28807328605200944\n",
      "(97, 8) fedorenko\n",
      "0.22160756501182033\n",
      "(60, 8) blank\n",
      "0.0\n",
      "(60, 8) blank\n",
      "0.0\n",
      "(60, 8) blank\n",
      "0.016666666666666666\n"
     ]
    }
   ],
   "source": [
    "compute_frac_sig(['-lt', '-mp', '-sp'], 'pereira','figure2')\n",
    "compute_frac_sig(['-lt', '-mp', '-sp'], 'fedorenko','figure2')\n",
    "compute_frac_sig(['-lt', '-mp', '-sp'], 'blank','figure2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13553, 8) pereira\n",
      "0.000662739322533137\n",
      "(13553, 8) pereira\n",
      "0.07619034767790638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4052165/3388948640.py:37: UserWarning: The palette list has more values (3) than needed (1), which may not be intended.\n",
      "  sns.barplot(plot_stats_df, hue='feature_extraction_arr', y='values', x='dataset', alpha=0.4, legend=False, errorbar=None, palette=color_palette,ax=ax)\n",
      "/tmp/ipykernel_4052165/3388948640.py:38: UserWarning: The palette list has more values (3) than needed (1), which may not be intended.\n",
      "  sns.stripplot(plot_stats_df, hue='feature_extraction_arr', y='values', x='dataset', dodge=True, size=10, alpha=0.8, legend=False, palette=color_palette,ax=ax)\n",
      "/tmp/ipykernel_4052165/3388948640.py:37: UserWarning: The palette list has more values (3) than needed (1), which may not be intended.\n",
      "  sns.barplot(plot_stats_df, hue='feature_extraction_arr', y='values', x='dataset', alpha=0.4, legend=False, errorbar=None, palette=color_palette,ax=ax)\n",
      "/tmp/ipykernel_4052165/3388948640.py:38: UserWarning: The palette list has more values (3) than needed (1), which may not be intended.\n",
      "  sns.stripplot(plot_stats_df, hue='feature_extraction_arr', y='values', x='dataset', dodge=True, size=10, alpha=0.8, legend=False, palette=color_palette,ax=ax)\n"
     ]
    }
   ],
   "source": [
    "compute_frac_sig(['-lt'], 'pereira','synt', 'syntax', ymax=50)\n",
    "compute_frac_sig(['-lt'], 'pereira','glove', 'glove', ymax=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llama\n",
      "(13553, 8) pereira\n",
      "0.007511045655375552\n",
      "(13553, 8) pereira\n",
      "0.024374079528718704\n",
      "(13553, 8) pereira\n",
      "0.0529501345526606\n",
      "(97, 8) fedorenko\n",
      "0.03333333333333333\n",
      "(97, 8) fedorenko\n",
      "0.06\n",
      "(97, 8) fedorenko\n",
      "0.04666666666666666\n",
      "(60, 8) blank\n",
      "0.0\n",
      "(60, 8) blank\n",
      "0.0\n",
      "(60, 8) blank\n",
      "0.0\n",
      "rwkv\n",
      "(13553, 8) pereira\n",
      "0.005522827687776141\n",
      "(13553, 8) pereira\n",
      "0.002430370977159241\n",
      "(13553, 8) pereira\n",
      "0.0246790398568884\n",
      "(97, 8) fedorenko\n",
      "0.024444444444444442\n",
      "(97, 8) fedorenko\n",
      "0.04666666666666666\n",
      "(97, 8) fedorenko\n",
      "0.06888888888888889\n",
      "(60, 8) blank\n",
      "0.0\n",
      "(60, 8) blank\n",
      "0.0\n",
      "(60, 8) blank\n",
      "0.0\n",
      "roberta-large\n",
      "(13553, 8) pereira\n",
      "7.363770250368188e-05\n",
      "(13553, 8) pereira\n",
      "0.04657064207450131\n",
      "(13553, 8) pereira\n",
      "0.04194303294805265\n",
      "(97, 8) fedorenko\n",
      "0.0\n",
      "(97, 8) fedorenko\n",
      "0.04666666666666666\n",
      "(97, 8) fedorenko\n",
      "0.057777777777777775\n",
      "(60, 8) blank\n",
      "0.0\n",
      "(60, 8) blank\n",
      "0.0\n",
      "(60, 8) blank\n",
      "0.0\n",
      "gpt2xl\n",
      "(13553, 8) pereira\n",
      "0.000589101620029455\n",
      "(13553, 8) pereira\n",
      "0.014311310339560169\n",
      "(13553, 8) pereira\n",
      "0.03411199099383911\n",
      "(97, 8) fedorenko\n",
      "0.04666666666666666\n",
      "(97, 8) fedorenko\n",
      "0.04666666666666666\n",
      "(97, 8) fedorenko\n",
      "0.04666666666666666\n",
      "(60, 8) blank\n",
      "0.0\n",
      "(60, 8) blank\n",
      "0.0\n",
      "(60, 8) blank\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "for model in model_names:\n",
    "    print(model)\n",
    "    compute_frac_sig(['-lt', '-mp', '-sp'], 'pereira', 'figure4', model)\n",
    "    compute_frac_sig(['-lt', '-mp', '-sp'], 'fedorenko', 'figure4', model)\n",
    "    compute_frac_sig(['-lt', '-mp', '-sp'], 'blank', 'figure4', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llama\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home3/ebrahim2/beyond-brainscore/analyze_results/figures_code/figures_data/figure4/blocked_pvalues_pereira_Llama.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m model_names:\n\u001b[32m      2\u001b[39m     \u001b[38;5;28mprint\u001b[39m(model)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[43mcompute_frac_sig\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m-lt\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m-mp\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m-sp\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpereira\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfigure4\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m     compute_frac_sig([\u001b[33m'\u001b[39m\u001b[33m-lt\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m-mp\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m-sp\u001b[39m\u001b[33m'\u001b[39m], \u001b[33m'\u001b[39m\u001b[33mfedorenko\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mfigure4\u001b[39m\u001b[33m'\u001b[39m, model, chunked=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      5\u001b[39m     compute_frac_sig([\u001b[33m'\u001b[39m\u001b[33m-lt\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m-mp\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m-sp\u001b[39m\u001b[33m'\u001b[39m], \u001b[33m'\u001b[39m\u001b[33mblank\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mfigure4\u001b[39m\u001b[33m'\u001b[39m, model, chunked=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mcompute_frac_sig\u001b[39m\u001b[34m(feature_extraction_arr, dataset, figure_folder, llm_name, ymax, chunked)\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     10\u001b[39m     df_name = \u001b[33m'\u001b[39m\u001b[33mpvalues\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m/home3/ebrahim2/beyond-brainscore/analyze_results/figures_code/figures_data/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfigure_folder\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdf_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdataset\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mllm_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m fig, ax = plt.subplots(\u001b[32m1\u001b[39m,\u001b[32m1\u001b[39m,figsize=(\u001b[32m3\u001b[39m,\u001b[32m4\u001b[39m))\n\u001b[32m     14\u001b[39m plot_stats_df = {\u001b[33m'\u001b[39m\u001b[33mvalues\u001b[39m\u001b[33m'\u001b[39m: [], \u001b[33m'\u001b[39m\u001b[33mfeature_extraction_arr\u001b[39m\u001b[33m'\u001b[39m: [], \u001b[33m'\u001b[39m\u001b[33mdataset\u001b[39m\u001b[33m'\u001b[39m: []}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm_brain_new/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm_brain_new/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm_brain_new/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm_brain_new/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm_brain_new/lib/python3.11/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(\n\u001b[32m    874\u001b[39m             handle,\n\u001b[32m    875\u001b[39m             ioargs.mode,\n\u001b[32m    876\u001b[39m             encoding=ioargs.encoding,\n\u001b[32m    877\u001b[39m             errors=errors,\n\u001b[32m    878\u001b[39m             newline=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    879\u001b[39m         )\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/home3/ebrahim2/beyond-brainscore/analyze_results/figures_code/figures_data/figure4/blocked_pvalues_pereira_Llama.csv'"
     ]
    }
   ],
   "source": [
    "for model in model_names:\n",
    "    print(model)\n",
    "    compute_frac_sig(['-lt', '-mp', '-sp'], 'pereira', 'figure4', model, chunked=True)\n",
    "    compute_frac_sig(['-lt', '-mp', '-sp'], 'fedorenko', 'figure4', model, chunked=True)\n",
    "    compute_frac_sig(['-lt', '-mp', '-sp'], 'blank', 'figure4', model, chunked=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for model in \n",
    "compute_frac_sig(['-lt', '-mp', '-sp'], 'pereira', 4, 'gpt2xl')\n",
    "compute_frac_sig(['-lt', '-mp', '-sp'], 'fedorenko', 4, 'gpt2xl')\n",
    "compute_frac_sig(['-lt', '-mp', '-sp'], 'blank', 4, 'gpt2xl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llama\n",
      "(13553, 8) pereira\n",
      "0.007511045655375552\n",
      "(13553, 8) pereira\n",
      "0.024374079528718704\n",
      "(13553, 8) pereira\n",
      "0.0529501345526606\n",
      "(97, 8) fedorenko\n",
      "0.03333333333333333\n",
      "(97, 8) fedorenko\n",
      "0.06\n",
      "(97, 8) fedorenko\n",
      "0.04666666666666666\n",
      "(60, 8) blank\n",
      "0.0\n",
      "(60, 8) blank\n",
      "0.0\n",
      "(60, 8) blank\n",
      "0.0\n",
      "rwkv\n",
      "(13553, 8) pereira\n",
      "0.005522827687776141\n",
      "(13553, 8) pereira\n",
      "0.002430370977159241\n",
      "(13553, 8) pereira\n",
      "0.0246790398568884\n",
      "(97, 8) fedorenko\n",
      "0.024444444444444442\n",
      "(97, 8) fedorenko\n",
      "0.04666666666666666\n",
      "(97, 8) fedorenko\n",
      "0.06888888888888889\n",
      "(60, 8) blank\n",
      "0.0\n",
      "(60, 8) blank\n",
      "0.0\n",
      "(60, 8) blank\n",
      "0.0\n",
      "roberta-large\n",
      "(13553, 8) pereira\n",
      "7.363770250368188e-05\n",
      "(13553, 8) pereira\n",
      "0.04657064207450131\n",
      "(13553, 8) pereira\n",
      "0.04194303294805265\n",
      "(97, 8) fedorenko\n",
      "0.0\n",
      "(97, 8) fedorenko\n",
      "0.04666666666666666\n",
      "(97, 8) fedorenko\n",
      "0.057777777777777775\n",
      "(60, 8) blank\n",
      "0.0\n",
      "(60, 8) blank\n",
      "0.0\n",
      "(60, 8) blank\n",
      "0.0\n",
      "gpt2xl\n",
      "(13553, 8) pereira\n",
      "0.000589101620029455\n",
      "(13553, 8) pereira\n",
      "0.014311310339560169\n",
      "(13553, 8) pereira\n",
      "0.03411199099383911\n",
      "(97, 8) fedorenko\n",
      "0.04666666666666666\n",
      "(97, 8) fedorenko\n",
      "0.04666666666666666\n",
      "(97, 8) fedorenko\n",
      "0.04666666666666666\n",
      "(60, 8) blank\n",
      "0.0\n",
      "(60, 8) blank\n",
      "0.0\n",
      "(60, 8) blank\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "for model in model_names:\n",
    "    print(model)\n",
    "    compute_frac_sig(['-lt', '-mp', '-sp'], 'pereira', 'figure4', model)\n",
    "    compute_frac_sig(['-lt', '-mp', '-sp'], 'fedorenko', 'figure4', model)\n",
    "    compute_frac_sig(['-lt', '-mp', '-sp'], 'blank', 'figure4', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13553, 8) pereira\n",
      "0.0\n",
      "(13553, 8) pereira\n",
      "0.0\n",
      "(13553, 8) pereira\n",
      "0.0\n",
      "(97, 8) fedorenko\n",
      "0.0\n",
      "(97, 8) fedorenko\n",
      "0.0\n",
      "(97, 8) fedorenko\n",
      "0.0\n",
      "(60, 8) blank\n",
      "0.0\n",
      "(60, 8) blank\n",
      "0.0\n",
      "(60, 8) blank\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "compute_frac_sig(['-lt', '-mp', '-sp'], 'pereira','figure5')\n",
    "compute_frac_sig(['-lt', '-mp', '-sp'], 'fedorenko','figure5')\n",
    "compute_frac_sig(['-lt', '-mp', '-sp'], 'blank','figure5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_brain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
