{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import ttest_rel\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pereira_shuffled_noL2custom_': 'OASM better: 0.0005829879526030354',\n",
       " 'pereira_shuffled_noL2custom_-mp': 'OASM better: 8.415461363884617e-06',\n",
       " 'pereira_shuffled_noL2custom_-sp': 'OASM better: 6.845450682602247e-06',\n",
       " 'pereira_shuffled_': 'OASM better: 0.0012114104713784794',\n",
       " 'pereira_shuffled_-mp': 'OASM better: 6.857022634777965e-05',\n",
       " 'pereira_shuffled_-sp': 'OASM better: 0.00025202230434096434',\n",
       " 'pereira_contig_noL2custom_': 'GPT2XL better: 0.0006467004109932069',\n",
       " 'pereira_contig_noL2custom_-mp': 'GPT2XL better: 0.000853685097633342',\n",
       " 'pereira_contig_noL2custom_-sp': 'GPT2XL better: 0.0009804389292874375',\n",
       " 'pereira_contig_': 'GPT2XL better: 0.0005507034926934181',\n",
       " 'pereira_contig_-mp': 'GPT2XL better: 0.00043633780032063205',\n",
       " 'pereira_contig_-sp': 'GPT2XL better: 0.000749761231008731',\n",
       " 'blank_shuffled_noL2custom_': 'OASM better: 4.080268110718511e-05',\n",
       " 'blank_shuffled_noL2custom_-mp': 'OASM better: 5.494779319878125e-05',\n",
       " 'blank_shuffled_noL2custom_-sp': 'OASM better: 4.099319566314164e-05',\n",
       " 'blank_shuffled_': 'OASM better: 2.3882156852822966e-05',\n",
       " 'blank_shuffled_-mp': 'OASM better: 8.085436478387584e-06',\n",
       " 'blank_shuffled_-sp': 'OASM better: 5.065788351032323e-06',\n",
       " 'blank_contig_noL2custom_': 'GPT2XL better: 0.042557786645799595',\n",
       " 'blank_contig_noL2custom_-mp': 'GPT2XL better: 0.028582309946293804',\n",
       " 'blank_contig_noL2custom_-sp': 'GPT2XL better: 0.06741694267645179',\n",
       " 'blank_contig_': 'GPT2XL better: 0.17666437357532813',\n",
       " 'blank_contig_-mp': 'GPT2XL better: 0.09541056450782429',\n",
       " 'blank_contig_-sp': 'GPT2XL better: 0.08370125187143239',\n",
       " 'fedorenko_shuffled_noL2custom_': 'OASM better: 0.17428984494389987',\n",
       " 'fedorenko_shuffled_noL2custom_-mp': 'OASM better: 0.14984064363760666',\n",
       " 'fedorenko_shuffled_noL2custom_-sp': 'OASM better: 0.08886418888874652',\n",
       " 'fedorenko_shuffled_': 'OASM better: 0.6055074461074732',\n",
       " 'fedorenko_shuffled_-mp': 'OASM better: 0.8667737263978292',\n",
       " 'fedorenko_shuffled_-sp': 'OASM better: 0.5213476743362989',\n",
       " 'fedorenko_contig_noL2custom_': 'GPT2XL better: 0.020910561747873906',\n",
       " 'fedorenko_contig_noL2custom_-mp': 'GPT2XL better: 0.03502934897938671',\n",
       " 'fedorenko_contig_noL2custom_-sp': 'GPT2XL better: 0.02277331666216007',\n",
       " 'fedorenko_contig_': 'GPT2XL better: 0.006192779292894172',\n",
       " 'fedorenko_contig_-mp': 'GPT2XL better: 0.005745648561518914',\n",
       " 'fedorenko_contig_-sp': 'GPT2XL better: 0.0064008918070520655'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_pvalues = {}\n",
    "for dataset in ['pereira', 'blank', 'fedorenko']:\n",
    "    for shuffle_str in ['shuffled', 'contig']:\n",
    "        for noL2_str in ['_noL2custom', '']:\n",
    "            results = pd.read_csv(f'/home2/ebrahim/beyond-brainscore/analyze_results/figures_code/figures_data/figure1/{dataset}_pearson_r{noL2_str}_{shuffle_str}.csv')\n",
    "            for fe in ['', '-mp', '-sp']:\n",
    "                results_gpt2xl = results.loc[results.Model==f'GPT2-XL{fe}']['perf'].to_numpy()\n",
    "                results_oasm = results.loc[results.Model=='OASM']['perf'].to_numpy()\n",
    "                result = ttest_rel(results_gpt2xl, results_oasm)\n",
    "                if np.mean(results_oasm) > np.mean(results_gpt2xl):\n",
    "                    store_pvalues[f\"{dataset}_{shuffle_str}{noL2_str}_{fe}\"] = f\"OASM better: {result.pvalue}\"\n",
    "                else:\n",
    "                    store_pvalues[f\"{dataset}_{shuffle_str}{noL2_str}_{fe}\"] = f\"GPT2XL better: {result.pvalue}\"\n",
    "store_pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paired_t_test(x, y):\n",
    "    \"\"\"\n",
    "    Compute the t-score for a paired t-test.\n",
    "\n",
    "    Parameters:\n",
    "    - x: numpy array of shape (n,), the first set of measurements.\n",
    "    - y: numpy array of shape (n,), the second set of measurements.\n",
    "\n",
    "    Returns:\n",
    "    - t_score: float, the t-score for the paired t-test.\n",
    "    \"\"\"\n",
    "    if len(x) != len(y):\n",
    "        raise ValueError(\"Input arrays must have the same length.\")\n",
    "    \n",
    "    # Calculate the differences\n",
    "    differences = x - y\n",
    "    \n",
    "    # Mean and standard deviation of the differences\n",
    "    mean_diff = np.mean(differences)\n",
    "    std_diff = np.std(differences, ddof=1)  # Sample standard deviation (ddof=1)\n",
    "    \n",
    "    # Number of samples\n",
    "    n = len(differences)\n",
    "    \n",
    "    # Compute the t-score\n",
    "    t_score = mean_diff / (std_diff / np.sqrt(n))\n",
    "    \n",
    "    return t_score, mean_diff, std_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08346577 0.04533634 0.06363695 0.08628033 0.01109693]\n",
      "[0.07385403 0.05178941 0.05785515 0.06925373 0.01109693]\n",
      "[0.08099617 0.05677894 0.04873938 0.07278461 0.01109693]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'pereira_-lt': 'GPT2XL better: 0.004724223518335061',\n",
       " 'pereira_-mp': 'GPT2XL better: 0.13243890812810272',\n",
       " 'pereira_-sp': 'GPT2XL better: 0.014500470367014146',\n",
       " 'blank_-lt': 'Simple better: 0.013885040925368124',\n",
       " 'blank_-mp': 'Simple better: 0.00904289156248817',\n",
       " 'blank_-sp': 'Simple better: 0.01127266136623814',\n",
       " 'fedorenko_-lt': 'GPT2XL better: 0.7785868321863119',\n",
       " 'fedorenko_-mp': 'GPT2XL better: 0.5708588256662082',\n",
       " 'fedorenko_-sp': 'GPT2XL better: 0.520582845367957'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_pvalues = {}\n",
    "for dataset in ['pereira', 'blank', 'fedorenko']:\n",
    "    for fe in ['-lt', '-mp', '-sp']:\n",
    "        results = pd.read_csv(f'/home2/ebrahim/beyond-brainscore/analyze_results/figures_code/figures_data/figure4/{dataset}_pearson_r.csv')\n",
    "        results_gpt2xl = results.loc[results.Model==f'GPT2XL{fe}']['perf'].to_numpy()\n",
    "        results_simple = results.loc[results.Model=='Simple']['perf'].to_numpy()\n",
    "        result = ttest_rel(results_gpt2xl, results_simple)\n",
    "        \n",
    "                    \n",
    "        if np.mean(results_simple) > np.mean(results_gpt2xl):\n",
    "            store_pvalues[f\"{dataset}_{fe}\"] = f\"Simple better: {result.pvalue}\"\n",
    "        else:\n",
    "            store_pvalues[f\"{dataset}_{fe}\"] = f\"GPT2XL better: {result.pvalue}\"\n",
    "            \n",
    "store_pvalues\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_frac_sig(feature_extraction_arr, dataset, figure_num):\n",
    "    \n",
    "    df = pd.read_csv(f'/home2/ebrahim/beyond-brainscore/analyze_results/figures_code/figures_data/figure{figure_num}/pvalues_{dataset}.csv')\n",
    "    \n",
    "    for fe in feature_extraction_arr: \n",
    "        \n",
    "        df_fe = df.loc[df.fe==fe].copy()\n",
    "        df_fe['pval_sig'] = np.where(df_fe['pval']<0.05, 1, 0)\n",
    "        df_fe['pval_gpt2xl_sig'] = np.where(df_fe['pval_gpt2xl_sig']<0.05, 1, 0)\n",
    "        \n",
    "        print(df_fe.groupby('subject')['pval_gpt2xl_sig'].sum())\n",
    "        \n",
    "        df_fe = df_fe.loc[df_fe['pval_gpt2xl_sig'] == 1]\n",
    "        \n",
    "        print(df_fe.groupby('subject')['pval_sig'].sum())\n",
    "\n",
    "        # Calculate the mean proportion of significant p-values per subject\n",
    "        subject_means = df_fe.groupby('subject')['pval_sig'].mean()\n",
    "        \n",
    "    \n",
    "        # Calculate the overall mean and standard error\n",
    "        overall_mean = subject_means.mean() * 100  # Convert to percentage\n",
    "        \n",
    "        std_error = (subject_means.std() / np.sqrt(len(subject_means))) * 100  # Convert to percentage\n",
    "\n",
    "        # Print the results with two significant digits\n",
    "        print(f\"{overall_mean:.3g} {std_error:.3g}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11173\n",
      "2614\n",
      "21.8 9.1%\n",
      "10334\n",
      "2165\n",
      "18.8 7.94%\n",
      "10499\n",
      "2822\n",
      "24.1 9.86%\n",
      "52\n",
      "25\n",
      "54.3 10.8%\n",
      "52\n",
      "30\n",
      "54.7 9.25%\n",
      "56\n",
      "25\n",
      "39.5 14.3%\n",
      "2\n",
      "0\n",
      "0 nan%\n",
      "22\n",
      "0\n",
      "0 0%\n",
      "17\n",
      "0\n",
      "0 0%\n"
     ]
    }
   ],
   "source": [
    "compute_frac_sig(['-lt', '-mp', '-sp'], 'pereira',2)\n",
    "compute_frac_sig(['-lt', '-mp', '-sp'], 'fedorenko',2)\n",
    "compute_frac_sig(['-lt', '-mp', '-sp'], 'blank',2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.133 0.104%\n",
      "0.895 0.798%\n",
      "0.713 0.435%\n",
      "0 0%\n",
      "3.78 2.51%\n",
      "2.5 2.5%\n",
      "13.3 2.04%\n",
      "23.3 8.5%\n",
      "33.3 12.6%\n"
     ]
    }
   ],
   "source": [
    "compute_frac_sig(['-lt', '-mp', '-sp'], 'pereira', 4)\n",
    "compute_frac_sig(['-lt', '-mp', '-sp'], 'fedorenko', 4)\n",
    "compute_frac_sig(['-lt', '-mp', '-sp'], 'blank', 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0%\n",
      "0 0%\n",
      "0 0%\n",
      "0 0%\n",
      "0 0%\n",
      "0 0%\n",
      "0 0%\n",
      "0 0%\n",
      "0 0%\n"
     ]
    }
   ],
   "source": [
    "compute_frac_sig(['-lt', '-mp', '-sp'], 'pereira',5)\n",
    "compute_frac_sig(['-lt', '-mp', '-sp'], 'fedorenko',5)\n",
    "compute_frac_sig(['-lt', '-mp', '-sp'], 'blank',5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_brain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
