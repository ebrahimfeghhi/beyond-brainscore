{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import wilcoxon\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['Llama', 'rwkv', 'roberta-large', 'gpt2xl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wilcoxon Signed-Rank Test:\n",
      "Statistic: 0.0\n",
      "P-value: 0.03125\n"
     ]
    }
   ],
   "source": [
    "# Example data for 5 participants\n",
    "condition_pre = np.array([0.6, 0.7, 0.8, 0.5, 0.9])  # Pre-intervention scores\n",
    "condition_post = np.array([0.7, 0.8, 0.85, 0.6, 0.95])  # Post-intervention scores\n",
    "\n",
    "# Perform the Wilcoxon signed-rank test\n",
    "stat, p_value = wilcoxon(condition_pre, condition_post, alternative='less')\n",
    "\n",
    "# Output the results\n",
    "print(\"Wilcoxon Signed-Rank Test:\")\n",
    "print(f\"Statistic: {stat}\")\n",
    "print(f\"P-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/ebrahim/miniconda3/envs/llm_brain/lib/python3.11/site-packages/scipy/stats/_wilcoxon.py:199: UserWarning: Sample size too small for normal approximation.\n",
      "  temp = _wilcoxon_iv(x, y, zero_method, correction, alternative, method, axis)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'pereira_shuffled_noL2custom_': 'OASM better: 1.0',\n",
       " 'pereira_shuffled_noL2custom_-mp': 'OASM better: 1.0',\n",
       " 'pereira_shuffled_noL2custom_-sp': 'OASM better: 1.0',\n",
       " 'pereira_shuffled_': 'OASM better: 1.0',\n",
       " 'pereira_shuffled_-mp': 'OASM better: 1.0',\n",
       " 'pereira_shuffled_-sp': 'OASM better: 0.9990234375',\n",
       " 'pereira_contig_noL2custom_': 'GPT2XL better: 0.0009765625',\n",
       " 'pereira_contig_noL2custom_-mp': 'GPT2XL better: 0.0009765625',\n",
       " 'pereira_contig_noL2custom_-sp': 'GPT2XL better: 0.0009765625',\n",
       " 'pereira_contig_': 'GPT2XL better: 0.0009765625',\n",
       " 'pereira_contig_-mp': 'GPT2XL better: 0.0009765625',\n",
       " 'pereira_contig_-sp': 'GPT2XL better: 0.0009765625',\n",
       " 'blank_shuffled_noL2custom_': 'OASM better: 1.0',\n",
       " 'blank_shuffled_noL2custom_-mp': 'OASM better: 1.0',\n",
       " 'blank_shuffled_noL2custom_-sp': 'OASM better: 1.0',\n",
       " 'blank_shuffled_': 'OASM better: 1.0',\n",
       " 'blank_shuffled_-mp': 'OASM better: 1.0',\n",
       " 'blank_shuffled_-sp': 'OASM better: 1.0',\n",
       " 'blank_contig_noL2custom_': 'GPT2XL better: 0.033944577430914495',\n",
       " 'blank_contig_noL2custom_-mp': 'GPT2XL better: 0.03125',\n",
       " 'blank_contig_noL2custom_-sp': 'GPT2XL better: 0.03125',\n",
       " 'blank_contig_': 'GPT2XL better: 0.0625',\n",
       " 'blank_contig_-mp': 'GPT2XL better: 0.0625',\n",
       " 'blank_contig_-sp': 'GPT2XL better: 0.0625',\n",
       " 'fedorenko_shuffled_noL2custom_': 'OASM better: 0.9375',\n",
       " 'fedorenko_shuffled_noL2custom_-mp': 'OASM better: 0.9375',\n",
       " 'fedorenko_shuffled_noL2custom_-sp': 'OASM better: 0.96875',\n",
       " 'fedorenko_shuffled_': 'OASM better: 0.78125',\n",
       " 'fedorenko_shuffled_-mp': 'OASM better: 0.59375',\n",
       " 'fedorenko_shuffled_-sp': 'OASM better: 0.78125',\n",
       " 'fedorenko_contig_noL2custom_': 'GPT2XL better: 0.03125',\n",
       " 'fedorenko_contig_noL2custom_-mp': 'GPT2XL better: 0.03125',\n",
       " 'fedorenko_contig_noL2custom_-sp': 'GPT2XL better: 0.03125',\n",
       " 'fedorenko_contig_': 'GPT2XL better: 0.03125',\n",
       " 'fedorenko_contig_-mp': 'GPT2XL better: 0.03125',\n",
       " 'fedorenko_contig_-sp': 'GPT2XL better: 0.03125'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_pvalues = {}\n",
    "for dataset in ['pereira', 'blank', 'fedorenko']:\n",
    "    for shuffle_str in ['shuffled', 'contig']:\n",
    "        for noL2_str in ['_noL2custom', '']:\n",
    "            results = pd.read_csv(f'/home2/ebrahim/beyond-brainscore/analyze_results/figures_code/figures_data/figure1/{dataset}_pearson_r{noL2_str}_{shuffle_str}.csv')\n",
    "            for fe in ['', '-mp', '-sp']:\n",
    "                results_gpt2xl = results.loc[results.Model==f'GPT2-XL{fe}']['perf'].to_numpy()\n",
    "                results_oasm = results.loc[results.Model=='OASM']['perf'].to_numpy()\n",
    "                result = wilcoxon(results_gpt2xl, results_oasm, alternative='greater')\n",
    "                if np.mean(results_oasm) > np.mean(results_gpt2xl):\n",
    "                    store_pvalues[f\"{dataset}_{shuffle_str}{noL2_str}_{fe}\"] = f\"OASM better: {result.pvalue}\"\n",
    "                else:\n",
    "                    store_pvalues[f\"{dataset}_{shuffle_str}{noL2_str}_{fe}\"] = f\"GPT2XL better: {result.pvalue}\"\n",
    "store_pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pereira_-lt': 'GPT2XL better: 0.0029296875',\n",
       " 'pereira_-mp': 'GPT2XL better: 0.052734375',\n",
       " 'pereira_-sp': 'GPT2XL better: 0.013671875',\n",
       " 'blank_-lt': 'Simple better: 1.0',\n",
       " 'blank_-mp': 'Simple better: 1.0',\n",
       " 'blank_-sp': 'Simple better: 1.0',\n",
       " 'fedorenko_-lt': 'GPT2XL better: 0.59375',\n",
       " 'fedorenko_-mp': 'GPT2XL better: 0.5',\n",
       " 'fedorenko_-sp': 'GPT2XL better: 0.3125'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_pvalues = {}\n",
    "for dataset in ['pereira', 'blank', 'fedorenko']:\n",
    "    for fe in ['-lt', '-mp', '-sp']:\n",
    "        results = pd.read_csv(f'/home2/ebrahim/beyond-brainscore/analyze_results/figures_code/figures_data/figure4/{dataset}_pearson_r.csv')\n",
    "        results_gpt2xl = results.loc[results.Model==f'GPT2XL{fe}']['perf'].to_numpy()\n",
    "        results_simple = results.loc[results.Model=='Simple']['perf'].to_numpy()\n",
    "        result = wilcoxon(results_gpt2xl, results_simple, alternative='greater')\n",
    "        \n",
    "                    \n",
    "        if np.mean(results_simple) > np.mean(results_gpt2xl):\n",
    "            store_pvalues[f\"{dataset}_{fe}\"] = f\"Simple better: {result.pvalue}\"\n",
    "        else:\n",
    "            store_pvalues[f\"{dataset}_{fe}\"] = f\"GPT2XL better: {result.pvalue}\"\n",
    "            \n",
    "store_pvalues\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pereira_-lt': 'Simple better: 0.009765625',\n",
       " 'pereira_-mp': 'Simple better: 0.130859375',\n",
       " 'pereira_-sp': 'Simple better: 0.556640625',\n",
       " 'blank_-lt': 'Simple better: 0.0625',\n",
       " 'blank_-mp': 'Simple better: 0.125',\n",
       " 'blank_-sp': 'Simple better: 0.0625',\n",
       " 'fedorenko_-lt': 'Simple better: 0.3125',\n",
       " 'fedorenko_-mp': 'Simple better: 0.4375',\n",
       " 'fedorenko_-sp': 'Simple better: 0.3125'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_pvalues = {}\n",
    "for dataset in ['pereira', 'blank', 'fedorenko']:\n",
    "    for fe in ['-lt', '-mp', '-sp']:\n",
    "        results = pd.read_csv(f'/home2/ebrahim/beyond-brainscore/analyze_results/figures_code/figures_data/figure5/{dataset}_pearson_r.csv')\n",
    "        results_gpt2xl = results.loc[results.Model==f'GPT2XLU{fe}']['perf'].to_numpy()\n",
    "        results_simple = results.loc[results.Model=='Simple']['perf'].to_numpy()\n",
    "        result = wilcoxon(results_gpt2xl, results_simple)\n",
    "        \n",
    "        if np.mean(results_simple) > np.mean(results_gpt2xl):\n",
    "            store_pvalues[f\"{dataset}_{fe}\"] = f\"Simple better: {result.pvalue}\"\n",
    "        else:\n",
    "            store_pvalues[f\"{dataset}_{fe}\"] = f\"GPT2XL better: {result.pvalue}\"\n",
    "            \n",
    "store_pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_palette = sns.color_palette([\"gray\", \"blue\", 'black'])\n",
    "def compute_frac_sig(feature_extraction_arr, dataset, figure_num, llm_name=''):\n",
    "    \n",
    "    if len(llm_name) > 0:\n",
    "        llm_name = f\"_{llm_name}\"\n",
    "    \n",
    "    df = pd.read_csv(f'/home2/ebrahim/beyond-brainscore/analyze_results/figures_code/figures_data/figure{figure_num}/pvalues_{dataset}{llm_name}.csv')\n",
    "\n",
    "    \n",
    "    fig, ax = plt.subplots(1,1,figsize=(3,4))\n",
    "    plot_stats_df = {'values': [], 'feature_extraction_arr': [], 'dataset': []}\n",
    "    \n",
    "    for fe in feature_extraction_arr: \n",
    "        \n",
    "        df_fe = df.loc[df.fe==fe].copy()\n",
    "        print(df_fe.shape, dataset)\n",
    "        df_fe['pval_sig'] = np.where(df_fe['pval']<0.05, 1, 0)\n",
    "\n",
    "        df_fe['pval_LLM_sig'] = np.where(df_fe['pval_LLM_sig']<0.05, 1, 0)\n",
    "  \n",
    "        #df_fe = df_fe.loc[df_fe[f'pval_LLM_sig'] == 1]\n",
    "\n",
    "        if df_fe.shape[0] == 0:\n",
    "            print(f\"No significant voxels/electrodes/fROIs for {llm_name}{fe} for {dataset}\")\n",
    "    \n",
    "        # Calculate the mean proportion of significant p-values per subject\n",
    "        subject_means = df_fe.groupby('subject')['pval_sig'].mean()\n",
    "\n",
    "        plot_stats_df['values'].extend(np.array(subject_means)*100)\n",
    "        plot_stats_df['feature_extraction_arr'].extend(np.repeat(fe, len(subject_means)))\n",
    "        plot_stats_df['dataset'].extend(np.repeat(dataset, len(subject_means)))\n",
    "        \n",
    "        print(np.mean(subject_means))\n",
    "        \n",
    "        \n",
    "    plot_stats_df = pd.DataFrame(plot_stats_df)\n",
    "    sns.barplot(plot_stats_df, hue='feature_extraction_arr', y='values', x='dataset', alpha=0.4, legend=False, errorbar=None, palette=color_palette,ax=ax)\n",
    "    sns.stripplot(plot_stats_df, hue='feature_extraction_arr', y='values', x='dataset', dodge=True, size=10, alpha=0.8, legend=False, palette=color_palette,ax=ax)\n",
    "    sns.despine()\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_xticklabels('')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([0,50])\n",
    "    ax.set_yticklabels([0,50], fontsize=20)\n",
    "    ax.set_ylabel('')\n",
    "    fig.savefig(f'/home2/ebrahim/beyond-brainscore/analyze_results/figures_code/figures/new_figures/figure{figure_num}/sig/frac_sig_{dataset}_{llm_name}.png', bbox_inches='tight')\n",
    "    fig.savefig(f'/home2/ebrahim/beyond-brainscore/analyze_results/figures_code/figures/new_figures/figure{figure_num}/sig/frac_sig_{dataset}_{llm_name}.pdf', bbox_inches='tight')   \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13553, 8) pereira\n",
      "0.22026116324437695\n",
      "(13553, 8) pereira\n",
      "0.18504614886382037\n",
      "(13553, 8) pereira\n",
      "0.2336163474787043\n",
      "(97, 8) fedorenko\n",
      "0.2938416075650118\n",
      "(97, 8) fedorenko\n",
      "0.28807328605200944\n",
      "(97, 8) fedorenko\n",
      "0.22160756501182033\n",
      "(60, 8) blank\n",
      "0.0\n",
      "(60, 8) blank\n",
      "0.0\n",
      "(60, 8) blank\n",
      "0.016666666666666666\n"
     ]
    }
   ],
   "source": [
    "compute_frac_sig(['-lt', '-mp', '-sp'], 'pereira',2)\n",
    "compute_frac_sig(['-lt', '-mp', '-sp'], 'fedorenko',2)\n",
    "compute_frac_sig(['-lt', '-mp', '-sp'], 'blank',2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for model in \n",
    "compute_frac_sig(['-lt', '-mp', '-sp'], 'pereira', 4, 'gpt2xl')\n",
    "compute_frac_sig(['-lt', '-mp', '-sp'], 'fedorenko', 4, 'gpt2xl')\n",
    "compute_frac_sig(['-lt', '-mp', '-sp'], 'blank', 4, 'gpt2xl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llama\n",
      "(13553, 8) pereira\n",
      "(13553, 8) pereira\n",
      "(13553, 8) pereira\n",
      "(97, 8) fedorenko\n",
      "(97, 8) fedorenko\n",
      "(97, 8) fedorenko\n",
      "(60, 8) blank\n",
      "(60, 8) blank\n",
      "(60, 8) blank\n",
      "rwkv\n",
      "(13553, 8) pereira\n",
      "(13553, 8) pereira\n",
      "(13553, 8) pereira\n",
      "(97, 8) fedorenko\n",
      "(97, 8) fedorenko\n",
      "(97, 8) fedorenko\n",
      "(60, 8) blank\n",
      "(60, 8) blank\n",
      "(60, 8) blank\n",
      "roberta-large\n",
      "(13553, 8) pereira\n",
      "(13553, 8) pereira\n",
      "(13553, 8) pereira\n",
      "(97, 8) fedorenko\n",
      "(97, 8) fedorenko\n",
      "(97, 8) fedorenko\n",
      "(60, 8) blank\n",
      "(60, 8) blank\n",
      "(60, 8) blank\n",
      "gpt2xl\n",
      "(13553, 8) pereira\n",
      "(13553, 8) pereira\n",
      "(13553, 8) pereira\n",
      "(97, 8) fedorenko\n",
      "(97, 8) fedorenko\n",
      "(97, 8) fedorenko\n",
      "(60, 8) blank\n",
      "(60, 8) blank\n",
      "(60, 8) blank\n"
     ]
    }
   ],
   "source": [
    "for model in model_names:\n",
    "    print(model)\n",
    "    compute_frac_sig(['-lt', '-mp', '-sp'], 'pereira', 4, model)\n",
    "    compute_frac_sig(['-lt', '-mp', '-sp'], 'fedorenko', 4, model)\n",
    "    compute_frac_sig(['-lt', '-mp', '-sp'], 'blank', 4, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13553, 8) pereira\n",
      "0.0\n",
      "(13553, 8) pereira\n",
      "0.0\n",
      "(13553, 8) pereira\n",
      "0.0\n",
      "(97, 8) fedorenko\n",
      "0.0\n",
      "(97, 8) fedorenko\n",
      "0.0\n",
      "(97, 8) fedorenko\n",
      "0.0\n",
      "(60, 8) blank\n",
      "0.0\n",
      "(60, 8) blank\n",
      "0.0\n",
      "(60, 8) blank\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "compute_frac_sig(['-lt', '-mp', '-sp'], 'pereira',5)\n",
    "compute_frac_sig(['-lt', '-mp', '-sp'], 'fedorenko',5)\n",
    "compute_frac_sig(['-lt', '-mp', '-sp'], 'blank',5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_brain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
