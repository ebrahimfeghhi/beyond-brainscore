{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import brainio"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used code in the legacy folder to order the text and neural data. Basically, run_LLM.py and run_funcs.py\n",
    "in the activations folder are used to save model activations in a pickle file format. Each pickle file\n",
    "is labeled according to the expriment, passage category, and passage label. The reason I did this is because\n",
    "that's how data in Schrimpf was saved (and I originally wanted to maintain consistency). Next, each pickle file is\n",
    "loaded, and the passage category and label in the file are used to index the neural data. This is done \n",
    "in saving_data.py and saving_funcs.py. I saved the indices into reordered_idxs.npy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc_file = '/data/LLMs/data_processed/pereira/dataset/pereira_all.nc'\n",
    "pereira_data = brainio.assemblies.DataAssembly.from_files(nc_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reordered_idxs = np.load('/data/LLMs/data_processed/pereira/dataset/reordered_idxs.npy') # just reorders the neural data to be in line wiht data labels and X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y_ordered = np.load('/data/LLMs/data_processed/pereira/dataset/y_pereira_both.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_all = pereira_data.data[reordered_idxs]\n",
    "subjects_all = pereira_data.subject\n",
    "networks_all = pereira_data.atlas\n",
    "col_to_coord1 = pereira_data.col_to_coord_1\n",
    "col_to_coord2 = pereira_data.col_to_coord_2\n",
    "col_to_coord3 = pereira_data.col_to_coord_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_all_243 = y_all[:243]\n",
    "nan_indices = np.where(np.isnan(y_all_243[0]))[0]\n",
    "cleaned_array_243 = np.delete(y_all_243, nan_indices, axis=1)\n",
    "subjects_all_243 = np.delete(subjects_all, nan_indices)\n",
    "networks_all_243 = np.delete(networks_all, nan_indices)\n",
    "col_to_coord1_243 = np.delete(col_to_coord1, nan_indices)\n",
    "col_to_coord2_243 = np.delete(col_to_coord2, nan_indices)\n",
    "col_to_coord3_243 = np.delete(col_to_coord3, nan_indices)\n",
    "np.save('/data/LLMs/data_processed/pereira/dataset/y_pereira_243.npy', cleaned_array_243)\n",
    "np.save('/data/LLMs/data_processed/pereira/dataset/subjects_243.npy', subjects_all_243)\n",
    "np.save('/data/LLMs/data_processed/pereira/dataset/networks_243.npy', networks_all_243)\n",
    "np.save('/data/LLMs/data_processed/pereira/dataset/col_to_coord_1_243.npy', col_to_coord1_243)\n",
    "np.save('/data/LLMs/data_processed/pereira/dataset/col_to_coord_2_243.npy', col_to_coord2_243)\n",
    "np.save('/data/LLMs/data_processed/pereira/dataset/col_to_coord_3_243.npy', col_to_coord3_243)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_all_384 = y_all[243:]\n",
    "nan_indices = np.where(np.isnan(y_all_384[0]))[0]\n",
    "cleaned_array_384 = np.delete(y_all_384, nan_indices, axis=1)\n",
    "subjects_all_384 = np.delete(subjects_all, nan_indices)\n",
    "networks_all_384 = np.delete(networks_all, nan_indices)\n",
    "col_to_coord1_384 = np.delete(col_to_coord1, nan_indices)\n",
    "col_to_coord2_384 = np.delete(col_to_coord2, nan_indices)\n",
    "col_to_coord3_384 = np.delete(col_to_coord3, nan_indices)\n",
    "np.save('/data/LLMs/data_processed/pereira/dataset/y_pereira_384.npy', cleaned_array_384)\n",
    "np.save('/data/LLMs/data_processed/pereira/dataset/subjects_384.npy', subjects_all_384)\n",
    "np.save('/data/LLMs/data_processed/pereira/dataset/networks_384.npy', networks_all_384)\n",
    "np.save('/data/LLMs/data_processed/pereira/dataset/col_to_coord_1_384.npy', col_to_coord1_384)\n",
    "np.save('/data/LLMs/data_processed/pereira/dataset/col_to_coord_2_384.npy', col_to_coord2_384)\n",
    "np.save('/data/LLMs/data_processed/pereira/dataset/col_to_coord_3_384.npy', col_to_coord3_384)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc_file = '/data/LLMs/data_processed/fedorenko/dataset/fedorenko.nc'\n",
    "fed_data = brainio.assemblies.DataAssembly.from_files(nc_file)\n",
    "y = np.save('/data/LLMs/data_processed/fedorenko/dataset/y_fedorenko', fed_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc_file = '/data/LLMs/data_processed/blank/dataset/blank.nc'\n",
    "blank_data = brainio.assemblies.DataAssembly.from_files(nc_file)\n",
    "#y = np.save('/data/LLMs/data_processed/fedorenko/dataset/y_fedorenko', fed_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
