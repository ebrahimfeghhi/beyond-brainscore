{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home3/ebrahim2/beyond-brainscore/analyze_results/figures_code/')\n",
    "from trained_untrained_results_funcs import find_best_layer,load_mean_sem_perf, loop_through_datasets\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_xl = np.load('/data/LLMs/data_processed/blank/acts/X_gpt2-xl.npz')\n",
    "data_labels = np.load('/data/LLMs/data_processed/blank/dataset/data_labels_blank.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_model_activations(model_acts, story_labels):\n",
    "\n",
    "    samples = model_acts.shape[0]\n",
    "    features = model_acts.shape[1]\n",
    "\n",
    "    shifted_versions = np.zeros((samples, features*4))\n",
    "    \n",
    "    zero_pad = np.zeros(features)\n",
    "        \n",
    "    stories = np.unique(story_labels)\n",
    "    for story in stories:\n",
    "        story_idxs = np.argwhere(story_labels==story)\n",
    "            \n",
    "        model_acts_story = model_acts[story_idxs].squeeze()\n",
    "        model_acts_story_2 = np.vstack((model_acts_story[1:, :], zero_pad)) # 2 second lag\n",
    "        model_acts_story_6 = np.vstack((zero_pad, model_acts_story[:-1, :])) # 6 second lag\n",
    "        model_acts_story_8 = np.vstack((zero_pad, zero_pad, model_acts_story[:-2, :])) # 8 second lag\n",
    "        \n",
    "        model_acts_time_lagged_story = np.hstack((model_acts_story_2, model_acts_story, model_acts_story_6, model_acts_story_8))\n",
    "        \n",
    "        shifted_versions[story_idxs.squeeze()] = model_acts_time_lagged_story\n",
    "        \n",
    "    return shifted_versions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_xl_stacked = {}\n",
    "for layer_name, layer in gpt2_xl.items():\n",
    "    \n",
    "    gpt2_xl_stacked[layer_name] = shift_model_activations(layer, data_labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"/data/LLMs/data_processed/blank/acts/X_timelagged-gpt2-xl.npz\", **gpt2_xl_stacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-mp pearson_r\n",
      "0.04587013265400093\n",
      "-mp out_of_sample_r2\n",
      "0.001949681925983652\n",
      "-sp pearson_r\n",
      "0.041225438850380935\n",
      "-sp out_of_sample_r2\n",
      "0.0011908467721330788\n",
      " pearson_r\n",
      "0.031958195735659514\n",
      " out_of_sample_r2\n",
      "0.00011144144901155857\n"
     ]
    }
   ],
   "source": [
    "subjects_storage = {}\n",
    "feature_extraction = ['-mp', '-sp', '']\n",
    "metric = ['pearson_r', 'out_of_sample_r2']\n",
    "for fe in feature_extraction:\n",
    "    for m in metric:\n",
    "        subjects_storage['blank'] = np.load(f\"/data/LLMs/data_processed/blank/dataset/subjects.npy\", allow_pickle=True)\n",
    "\n",
    "        layer_perf_dict, best_layer_blank, layer_perf_best, layer_perf_best_across_subject  = find_best_layer(np.arange(49), '', '', resultsPath='/data/LLMs/brainscore/results_blank/', \n",
    "                            subjects=subjects_storage['blank'],\n",
    "                            dataset='blank', perf=m, \n",
    "                            selected_network_indices = None, feature_extraction =fe, model_name='timelagged-gpt2-xl', seed_number=None, \n",
    "                            return_SE=False, niter=1)\n",
    "        \n",
    "        print(fe, m)\n",
    "        print(layer_perf_dict[best_layer_blank])\n",
    "        print(layer_perf_best_across_subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60,)\n"
     ]
    }
   ],
   "source": [
    "print(layer_perf_best.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.035582324570484755,\n",
       " 1: 0.03768965673582303,\n",
       " 2: 0.041607410569049506,\n",
       " 3: 0.04587013265400093,\n",
       " 4: 0.04224277698241717,\n",
       " 5: 0.03835332020773615,\n",
       " 6: 0.03300747642090639,\n",
       " 7: 0.02969561252318048,\n",
       " 8: 0.028682187144289762,\n",
       " 9: 0.027176770057543688,\n",
       " 10: 0.027271272225770415,\n",
       " 11: 0.02745013733654747,\n",
       " 12: 0.02640949966268622,\n",
       " 13: 0.026381127830513235,\n",
       " 14: 0.02584866615542982,\n",
       " 15: 0.025444682791340816,\n",
       " 16: 0.025028847972939323,\n",
       " 17: 0.02568691921229572,\n",
       " 18: 0.025349834474299716,\n",
       " 19: 0.024112924863530852,\n",
       " 20: 0.024747528286099253,\n",
       " 21: 0.023779697788066975,\n",
       " 22: 0.02302143091268056,\n",
       " 23: 0.023152685618536787,\n",
       " 24: 0.023821807418134777,\n",
       " 25: 0.02461639168983823,\n",
       " 26: 0.023396391804153892,\n",
       " 27: 0.021804243322758085,\n",
       " 28: 0.02199302536270511,\n",
       " 29: 0.021094771497439723,\n",
       " 30: 0.02149822604413648,\n",
       " 31: 0.021255935169157678,\n",
       " 32: 0.020325554336762072,\n",
       " 33: 0.020846279423530435,\n",
       " 34: 0.021120408907636418,\n",
       " 35: 0.02205776526712663,\n",
       " 36: 0.022149164366517312,\n",
       " 37: 0.019921141043504505,\n",
       " 38: 0.01875140787027736,\n",
       " 39: 0.016645288428310118,\n",
       " 40: 0.014453112269416984,\n",
       " 41: 0.01333527540597027,\n",
       " 42: 0.011742660715093337,\n",
       " 43: 0.010445036311028928,\n",
       " 44: 0.010191470604329959,\n",
       " 45: 0.008271139385795195,\n",
       " 46: 0.007470204306407063,\n",
       " 47: 0.004769549620491172,\n",
       " 48: 0.022943201295952988}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_perf_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_brain_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
