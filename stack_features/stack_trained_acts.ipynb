{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import itertools\n",
    "from matplotlib import pyplot as plt\n",
    "from helper_funcs import save_stacked, stack_combinations\n",
    "from copy import deepcopy\n",
    "base_path = '/home3/ebrahim2/' # replace with your base path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('beyond-brainscore/analyze_results/figures_code')\n",
    "from trained_untrained_results_funcs import find_best_layer, loop_through_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_gpt2xl_layer_dict = np.load(f\"{base_path}beyond-brainscore/analyze_results/figures_code/best_layer_sigma_info/best_gpt2xl_layer.npz\")\n",
    "best_pereira_layers = np.load(f\"{base_path}beyond-brainscore/analyze_results/figures_code/best_layer_sigma_info/best_layer_other_pereira.npz\")\n",
    "best_roberta_layers = np.load(f\"{base_path}beyond-brainscore/analyze_results/figures_code/best_layer_sigma_info/roberta-large.npz\")\n",
    "best_llama_layers = np.load(f\"{base_path}beyond-brainscore/analyze_results/figures_code/best_layer_sigma_info/Llama-3.2-3B-Instruct.npz\")\n",
    "best_rwkv_layers = np.load(f\"{base_path}beyond-brainscore/analyze_results/figures_code/best_layer_sigma_info/rwkv-4-3b-pile.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pereira_WN_model = np.load(\"/data/LLMs/data_processed/pereira/acts/X_word-num.npz\")['layer1']\n",
    "pereira_glove_sp = np.load(\"/data/LLMs/data_processed/pereira/acts/X_glove-sp.npz\")['layer_0']\n",
    "best_pos = {'384': 3.4, '243': 2.9}\n",
    "pereira_all_simple_models = {'WN': pereira_WN_model, 'glove': pereira_glove_sp}\n",
    "\n",
    "fedorenko_WP_model = np.load(\"/data/LLMs/data_processed/fedorenko/acts/X_pos.npz\")['layer_4.7']\n",
    "fedorenko_WP_model_pearsonr = np.load(\"/data/LLMs/data_processed/fedorenko/acts/X_pos.npz\")['layer_4.3']\n",
    "\n",
    "fed_glove_sp = np.load(\"/data/LLMs/data_processed/fedorenko/acts/X_glove-sp.npz\")['layer_0']\n",
    "fedorenko_all_simple_models = {'WP': fedorenko_WP_model, 'glove': fed_glove_sp}\n",
    "\n",
    "blank_pos_model = np.load(\"/data/LLMs/data_processed/blank/acts/X_pos.npz\")['layer_11'] \n",
    "blank_pos_model_pearsonr = np.load(\"/data/LLMs/data_processed/blank/acts/X_pos.npz\")['layer_12'] \n",
    "\n",
    "blank_WN_model = np.load(\"/data/LLMs/data_processed/blank/acts/X_WN.npz\")['layer1'] \n",
    "blank_glove_sp = np.load(\"/data/LLMs/data_processed/blank/acts/X_glove-sp.npz\")['layer_0']\n",
    "blank_all_simple_models = {'pos': blank_pos_model, 'WN': blank_WN_model, 'glove': blank_glove_sp}\n",
    "\n",
    "all_simple_models = {'pereira': pereira_all_simple_models, 'fedorenko': fedorenko_all_simple_models, 'blank': blank_all_simple_models}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WN [1]\n",
      "pos [4]\n",
      "glove [300]\n",
      "WN+pos [5]\n",
      "WN+glove [1, 300]\n",
      "pos+glove [4, 300]\n",
      "WN+pos+glove [5, 300]\n",
      "WN [1]\n",
      "pos [4]\n",
      "glove [300]\n",
      "WN+pos [5]\n",
      "WN+glove [1, 300]\n",
      "pos+glove [4, 300]\n",
      "WN+pos+glove [5, 300]\n",
      "WN [1]\n",
      "pos [4]\n",
      "glove [300]\n",
      "WN+pos [5]\n",
      "WN+glove [1, 300]\n",
      "pos+glove [4, 300]\n",
      "WN+pos+glove [5, 300]\n",
      "WN [1]\n",
      "pos [4]\n",
      "glove [300]\n",
      "WN+pos [5]\n",
      "WN+glove [1, 300]\n",
      "pos+glove [4, 300]\n",
      "WN+pos+glove [5, 300]\n",
      "WN [1]\n",
      "pos [4]\n",
      "glove [300]\n",
      "WN+pos [5]\n",
      "WN+glove [1, 300]\n",
      "pos+glove [4, 300]\n",
      "WN+pos+glove [5, 300]\n",
      "WN [1]\n",
      "pos [4]\n",
      "glove [300]\n",
      "WN+pos [5]\n",
      "WN+glove [1, 300]\n",
      "pos+glove [4, 300]\n",
      "WN+pos+glove [5, 300]\n",
      "WP [9]\n",
      "WP [9]\n",
      "WP [9]\n",
      "WN [1]\n",
      "pos [10]\n",
      "WN+pos [11]\n",
      "WN [1]\n",
      "pos [10]\n",
      "WN+pos [11]\n",
      "WN [1]\n",
      "pos [10]\n",
      "WN+pos [11]\n"
     ]
    }
   ],
   "source": [
    "save_stacked('', None, all_simple_models_save=deepcopy(all_simple_models), best_pos=best_pos, exclude_non_LLM=False)\n",
    "save_stacked('roberta-large', best_roberta_layers, all_simple_models_save=deepcopy(all_simple_models), best_pos=best_pos)\n",
    "save_stacked('Llama-3.2-3B-Instruct', best_llama_layers, all_simple_models_save=deepcopy(all_simple_models), best_pos=best_pos)\n",
    "save_stacked('rwkv-4-3b-pile', best_rwkv_layers, all_simple_models_save=deepcopy(all_simple_models), best_pos=best_pos)\n",
    "save_stacked('gpt2-xl', best_gpt2xl_layer_dict, all_simple_models_save=deepcopy(all_simple_models), best_pos=best_pos)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking for pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "PWR_pereira_384 = np.load(\"/data/LLMs/data_processed/pereira/acts/X_positional_WN_smooth.npz\")['layer_1.2']\n",
    "PWR_pereira_243 = np.load(\"/data/LLMs/data_processed/pereira/acts/X_positional_WN_smooth.npz\")['layer_0.5']\n",
    "\n",
    "np.savez('/data/LLMs/data_processed/pereira/acts/X_glove-sp_PWR_384', **{'layer_1': np.hstack((pereira_glove_sp, PWR_pereira_384))})\n",
    "np.savez('/data/LLMs/data_processed/pereira/acts/X_glove-sp_PWR_243', **{'layer_1': np.hstack((pereira_glove_sp, PWR_pereira_243))})\n",
    "\n",
    "np.savez('/data/LLMs/data_processed/fedorenko/acts/X_glove-sp_PWR', **{'layer_1': np.hstack((fed_glove_sp, fedorenko_WP_model_pearsonr))})\n",
    "\n",
    "np.savez('/data/LLMs/data_processed/blank/acts/X_glove-sp_PWR', **{'layer_1': np.hstack((blank_glove_sp, blank_pos_model_pearsonr))})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack syntax\n",
    "for fe in ['','-mp', '-sp']:\n",
    "    np.load(f'/data/LLMs/data_processed/pereira/acts/X_gpt2xl-syntax{fe}.npz')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_brain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
