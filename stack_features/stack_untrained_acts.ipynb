{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('/home2/ebrahim/beyond-brainscore/analyze_results/figures_code/')\n",
    "from trained_untrained_results_funcs import find_best_layer, loop_through_datasets, load_mean_sem_perf\n",
    "from plotting_functions import plot_across_subjects\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pdimport \n",
    "import sys\n",
    "sys.path.append('/home2/ebrahim/beyond-brainscore/')\n",
    "from banded_reg_func import himalaya_regression_caller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_seeds = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = ['243', '384']\n",
    "\n",
    "br_labels_dict = {}\n",
    "num_vox_dict = {}\n",
    "subjects_dict = {}\n",
    "\n",
    "data_processed_folder_pereira = f'/data/LLMs/data_processed/pereira/dataset'\n",
    "data_processed_folder_fed = f'/data/LLMs/data_processed/fedorenko/dataset'\n",
    "data_processed_folder_blank = f'/data/LLMs/data_processed/blank/dataset'\n",
    "\n",
    "subjects_storage = {}\n",
    "network_labels_storage = {}\n",
    "\n",
    "for e in exp:\n",
    "\n",
    "    bre = np.load(f'{data_processed_folder_pereira}/networks_{e}.npy', allow_pickle=True)\n",
    "    network_labels_storage[f\"pereira{e}\"]  = bre\n",
    "    num_vox_dict[e] = bre.shape[0]\n",
    "    subjects_storage[f\"pereira{e}\"] = np.load(f\"{data_processed_folder_pereira}/subjects_{e}.npy\", allow_pickle=True)\n",
    "\n",
    "subjects_storage['fedorenko']  = np.load(f\"{data_processed_folder_fed}/subjects.npy\", allow_pickle=True)\n",
    "subjects_storage['blank'] = np.load(f\"{data_processed_folder_blank}/subjects.npy\", allow_pickle=True)\n",
    "\n",
    "network_labels_storage['fedorenko'] = None\n",
    "network_labels_storage['blank'] = None\n",
    "\n",
    "subjects_arr_pereira = np.load(f\"{data_processed_folder_pereira}/subjects_complete.npy\", allow_pickle=True)\n",
    "networks_arr_pereira = np.load(f\"{data_processed_folder_pereira}/network_complete.npy\", allow_pickle=True)\n",
    "\n",
    "resultsPath_base = '/data/LLMs/brainscore/'\n",
    "                    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the best pos value for blank simple model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The code block below does two things. 1st, it resaves the best layer of the untrained model so that I can run it again,\n",
    "#### because I deleted the yhat values (due to storage space), and I need them now. Second, it stacks the best layer with the simple\n",
    "#### feature spaces and saves that also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SL = np.load('/data/LLMs/data_processed/pereira/acts/X_word-num.npz')['layer1']\n",
    "\n",
    "WP = np.load('/data/LLMs/data_processed/fedorenko/acts/X_pos.npz')['layer_4.7']\n",
    "\n",
    "WN_POS = np.load('/data/LLMs/data_processed/blank/acts/X_pos-WN.npz')[f'layer_11'] \n",
    "WN = np.expand_dims(WN_POS[:, 0],axis=-1)\n",
    "POS = WN_POS[:, 1:]\n",
    "np.savez('/data/LLMs/data_processed/blank/acts/X_POS.npz', **{'layer1': POS})\n",
    "np.savez('/data/LLMs/data_processed/blank/acts/X_WN.npz', **{'layer1': WN})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pereira  _243\n",
      "pereira  _384\n",
      "pereira -mp _243\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/data/LLMs/brainscore/results_pereira/untrained/pereira_gpt2-xl-untrained-mp-mp_m0_layer_0_1_243.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 21\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_seeds):\n\u001b[1;32m     18\u001b[0m     \n\u001b[1;32m     19\u001b[0m     \u001b[39m# load activations\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     X_untrained \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mload(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m/data/LLMs/data_processed/\u001b[39m\u001b[39m{\u001b[39;00md\u001b[39m}\u001b[39;00m\u001b[39m/acts/X_gpt2-xl-untrained\u001b[39m\u001b[39m{\u001b[39;00mfe\u001b[39m}\u001b[39;00m\u001b[39m_m\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m.npz\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m     gpt2_untrained_dict, gpt2_untrained_bl, gpt2_untrained_bl_perf  \u001b[39m=\u001b[39m find_best_layer(np\u001b[39m.\u001b[39;49marange(\u001b[39m49\u001b[39;49m), noL2_str\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m'\u001b[39;49m, exp\u001b[39m=\u001b[39;49mexp, \n\u001b[1;32m     22\u001b[0m                                             resultsPath\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mresultsPath_base\u001b[39m}\u001b[39;49;00m\u001b[39mresults_\u001b[39;49m\u001b[39m{\u001b[39;49;00md\u001b[39m}\u001b[39;49;00m\u001b[39m/untrained\u001b[39;49m\u001b[39m\"\u001b[39;49m, niter\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     23\u001b[0m                                             perf\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mout_of_sample_r2\u001b[39;49m\u001b[39m'\u001b[39;49m, feature_extraction\u001b[39m=\u001b[39;49mfe, selected_network_indices\u001b[39m=\u001b[39;49mlang_indices, \n\u001b[1;32m     24\u001b[0m                                             subjects\u001b[39m=\u001b[39;49msubjects, dataset\u001b[39m=\u001b[39;49md, model_name\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mgpt2-xl-untrained\u001b[39;49m\u001b[39m{\u001b[39;49;00mfe\u001b[39m}\u001b[39;49;00m\u001b[39m'\u001b[39;49m, seed_number\u001b[39m=\u001b[39;49mi)\n\u001b[1;32m     26\u001b[0m     X_best_layer \u001b[39m=\u001b[39m X_untrained[\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlayer_\u001b[39m\u001b[39m{\u001b[39;00mgpt2_untrained_bl\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m]\n\u001b[1;32m     28\u001b[0m     \u001b[39mif\u001b[39;00m d \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mpereira\u001b[39m\u001b[39m'\u001b[39m:\n",
      "File \u001b[0;32m~/beyond-brainscore/analyze_results/figures_code/trained_untrained_results_funcs.py:250\u001b[0m, in \u001b[0;36mfind_best_layer\u001b[0;34m(layer_range, noL2_str, exp, resultsPath, subjects, dataset, perf, selected_network_indices, feature_extraction, model_name, seed_number, return_SE, niter, median, shape_pereira_full, non_nan_indices_dict)\u001b[0m\n\u001b[1;32m    246\u001b[0m     seed_str \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    248\u001b[0m \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m layer_range:\n\u001b[0;32m--> 250\u001b[0m     layer_perf \u001b[39m=\u001b[39m load_perf(\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m{\u001b[39;49;00mresultsPath\u001b[39m}\u001b[39;49;00m\u001b[39m/\u001b[39;49m\u001b[39m{\u001b[39;49;00mdataset\u001b[39m}\u001b[39;49;00m\u001b[39m_\u001b[39;49m\u001b[39m{\u001b[39;49;00mmodel_name\u001b[39m}\u001b[39;49;00m\u001b[39m{\u001b[39;49;00mfeature_extraction\u001b[39m}\u001b[39;49;00m\u001b[39m{\u001b[39;49;00mseed_str\u001b[39m}\u001b[39;49;00m\u001b[39m_layer_\u001b[39;49m\u001b[39m{\u001b[39;49;00ml\u001b[39m}\u001b[39;49;00m\u001b[39m_\u001b[39;49m\u001b[39m{\u001b[39;49;00mniter\u001b[39m}\u001b[39;49;00m\u001b[39m{\u001b[39;49;00mnoL2_str\u001b[39m}\u001b[39;49;00m\u001b[39m{\u001b[39;49;00mexp\u001b[39m}\u001b[39;49;00m\u001b[39m.npz\u001b[39;49m\u001b[39m'\u001b[39;49m, perf)\n\u001b[1;32m    252\u001b[0m     \u001b[39mif\u001b[39;00m dataset \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mpereira\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    253\u001b[0m         layer_perf \u001b[39m=\u001b[39m layer_perf[selected_network_indices]\n",
      "File \u001b[0;32m~/beyond-brainscore/analyze_results/figures_code/trained_untrained_results_funcs.py:104\u001b[0m, in \u001b[0;36mload_perf\u001b[0;34m(filepath, perf, clip_zero, return_SE, shape_pereira_full, non_nan_indices_dict, exp, dataset)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_perf\u001b[39m(filepath, perf, clip_zero\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, return_SE\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, shape_pereira_full\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, non_nan_indices_dict\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, exp\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m, dataset\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 104\u001b[0m     perf_arr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mnan_to_num(np\u001b[39m.\u001b[39;49mload(filepath)[perf])\n\u001b[1;32m    106\u001b[0m     \u001b[39mif\u001b[39;00m clip_zero:\n\u001b[1;32m    107\u001b[0m         \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mclip(perf_arr, \u001b[39m0\u001b[39m, np\u001b[39m.\u001b[39minf)\n",
      "File \u001b[0;32m~/miniconda3/envs/llm_brain/lib/python3.11/site-packages/numpy/lib/npyio.py:427\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    425\u001b[0m     own_fid \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    426\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 427\u001b[0m     fid \u001b[39m=\u001b[39m stack\u001b[39m.\u001b[39menter_context(\u001b[39mopen\u001b[39m(os_fspath(file), \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m    428\u001b[0m     own_fid \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \u001b[39m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/data/LLMs/brainscore/results_pereira/untrained/pereira_gpt2-xl-untrained-mp-mp_m0_layer_0_1_243.npz'"
     ]
    }
   ],
   "source": [
    "for d, fe, exp, subjects, networks in loop_through_datasets(dataset_arr=['pereira', 'fedorenko', 'blank'], \n",
    "                            feature_extraction_arr=['', '-mp', '-sp']):\n",
    "    \n",
    "    print(d, fe, exp)\n",
    "    \n",
    "    if networks is not None:\n",
    "        \n",
    "        lang_indices = np.argwhere(networks=='language').squeeze()\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        lang_indices = None\n",
    "        \n",
    "    save_acts = {}\n",
    "    save_acts_stacked = {}\n",
    "\n",
    "    for i in range(num_seeds):\n",
    "        \n",
    "        # load activations\n",
    "        X_untrained = np.load(f'/data/LLMs/data_processed/{d}/acts/X_gpt2-xl-untrained{fe}_m{i}.npz')\n",
    "        gpt2_untrained_dict, gpt2_untrained_bl, gpt2_untrained_bl_perf  = find_best_layer(np.arange(49), noL2_str='', exp=exp, \n",
    "                                                resultsPath=f\"{resultsPath_base}results_{d}/untrained\", niter=1,\n",
    "                                                perf='out_of_sample_r2', feature_extraction=fe, selected_network_indices=lang_indices, \n",
    "                                                subjects=subjects, dataset=d, model_name=f'gpt2-xl-untrained', seed_number=i)\n",
    "        \n",
    "        X_best_layer = X_untrained[f'layer_{gpt2_untrained_bl}']\n",
    "        \n",
    "        if d == 'pereira':\n",
    "            \n",
    "            best_pos = {'384': 3.4, '243': 2.9}\n",
    "            exp_no_underscore = exp.strip('_')\n",
    "            position = np.load(\"/data/LLMs/data_processed/pereira/acts/X_position.npz\")[f'layer_{best_pos[exp_no_underscore]}']\n",
    "            SP_SL = np.hstack((position, SL))\n",
    "            \n",
    "            save_acts_stacked[f\"m{i}_SP_SL_layer_{gpt2_untrained_bl}\"] = np.hstack((X_best_layer, SP_SL))\n",
    "            save_acts_stacked[f\"m{i}_SL_layer_{gpt2_untrained_bl}\"] = np.hstack((X_best_layer, SL))\n",
    "            save_acts_stacked[f\"m{i}_SP_layer_{gpt2_untrained_bl}\"] = np.hstack((X_best_layer, position))\n",
    "            \n",
    "        elif d == 'fedorenko':\n",
    "            save_acts_stacked[f\"m{i}_WP_layer_{gpt2_untrained_bl}\"]  = np.hstack((X_best_layer, WP))\n",
    "        else:\n",
    "            save_acts_stacked[f\"m{i}_POS_WN_layer_{gpt2_untrained_bl}\"]  = np.hstack((X_best_layer, WN_POS))\n",
    "            save_acts_stacked[f\"m{i}_POS_layer_{gpt2_untrained_bl}\"]  = np.hstack((X_best_layer, POS))\n",
    "            save_acts_stacked[f\"m{i}_WN_layer_{gpt2_untrained_bl}\"]  = np.hstack((X_best_layer, WN))\n",
    "            \n",
    "        save_acts[f\"m{i}_layer_{gpt2_untrained_bl}\"] = X_best_layer\n",
    "        \n",
    "\n",
    "    np.savez(f\"/data/LLMs/data_processed/{d}/acts/X_gpt2-xl-untrained{fe}-r2-best{exp}\", **save_acts)\n",
    "    np.savez(f\"/data/LLMs/data_processed/{d}/acts/X_gpt2-xl-untrained{fe}-var-par{exp}\", **save_acts_stacked)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_brain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
