{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('/home2/ebrahim/beyond-brainscore/analyze_results/figures_code/')\n",
    "from trained_untrained_results_funcs import find_best_layer, loop_through_datasets, load_mean_sem_perf\n",
    "from plotting_functions import plot_across_subjects\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pdimport \n",
    "import sys\n",
    "sys.path.append('/home2/ebrahim/beyond-brainscore/')\n",
    "from banded_reg_func import himalaya_regression_caller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_seeds = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = ['243', '384']\n",
    "\n",
    "br_labels_dict = {}\n",
    "num_vox_dict = {}\n",
    "subjects_dict = {}\n",
    "\n",
    "data_processed_folder_pereira = f'/data/LLMs/data_processed/pereira/dataset'\n",
    "data_processed_folder_fed = f'/data/LLMs/data_processed/fedorenko/dataset'\n",
    "data_processed_folder_blank = f'/data/LLMs/data_processed/blank/dataset'\n",
    "\n",
    "subjects_storage = {}\n",
    "network_labels_storage = {}\n",
    "\n",
    "for e in exp:\n",
    "\n",
    "    bre = np.load(f'{data_processed_folder_pereira}/networks_{e}.npy', allow_pickle=True)\n",
    "    network_labels_storage[f\"pereira{e}\"]  = bre\n",
    "    num_vox_dict[e] = bre.shape[0]\n",
    "    subjects_storage[f\"pereira{e}\"] = np.load(f\"{data_processed_folder_pereira}/subjects_{e}.npy\", allow_pickle=True)\n",
    "\n",
    "subjects_storage['fedorenko']  = np.load(f\"{data_processed_folder_fed}/subjects.npy\", allow_pickle=True)\n",
    "subjects_storage['blank'] = np.load(f\"{data_processed_folder_blank}/subjects.npy\", allow_pickle=True)\n",
    "\n",
    "network_labels_storage['fedorenko'] = None\n",
    "network_labels_storage['blank'] = None\n",
    "\n",
    "subjects_arr_pereira = np.load(f\"{data_processed_folder_pereira}/subjects_complete.npy\", allow_pickle=True)\n",
    "networks_arr_pereira = np.load(f\"{data_processed_folder_pereira}/network_complete.npy\", allow_pickle=True)\n",
    "\n",
    "resultsPath_base = '/data/LLMs/brainscore/'\n",
    "                    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the best pos value for blank simple model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The code block below does two things. 1st, it resaves the best layer of the untrained model so that I can run it again,\n",
    "#### because I deleted the yhat values (due to storage space), and I need them now. Second, it stacks the best layer with the simple\n",
    "#### feature spaces and saves that also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "SP_SL = np.load('/data/LLMs/data_processed/pereira/acts/X_positional_WN.npz')['layer1']\n",
    "SP = np.load('/data/LLMs/data_processed/pereira/acts/X_positional_simple.npz')['layer1']\n",
    "SL = np.load('/data/LLMs/data_processed/pereira/acts/X_word-num.npz')['layer1']\n",
    "\n",
    "WP = np.load('/data/LLMs/data_processed/fedorenko/acts/X_pos.npz')['layer_4.6']\n",
    "\n",
    "WN_POS = np.load('/data/LLMs/data_processed/blank/acts/X_pos-WN.npz')[f'layer_12'] # its word number and then positional\n",
    "WN = np.expand_dims(WN_POS[:, 0],axis=-1)\n",
    "POS = WN_POS[:, 1:]\n",
    "np.savez('/data/LLMs/data_processed/blank/acts/X_POS.npz', **{'layer1': POS})\n",
    "np.savez('/data/LLMs/data_processed/blank/acts/X_WN.npz', **{'layer1': WN})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pereira  _243\n",
      "pereira  _384\n",
      "pereira -mp _243\n",
      "pereira -mp _384\n",
      "pereira -sp _243\n",
      "pereira -sp _384\n",
      "fedorenko  \n",
      "fedorenko -mp \n",
      "fedorenko -sp \n",
      "blank  \n",
      "blank -mp \n",
      "blank -sp \n"
     ]
    }
   ],
   "source": [
    "for d, fe, exp, subjects, networks in loop_through_datasets(dataset_arr=['pereira', 'fedorenko', 'blank'], \n",
    "                            feature_extraction_arr=['', '-mp', '-sp']):\n",
    "    \n",
    "    print(d, fe, exp)\n",
    "    \n",
    "    if networks is not None:\n",
    "        \n",
    "        lang_indices = np.argwhere(networks=='language').squeeze()\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        lang_indices = None\n",
    "        \n",
    "    save_acts = {}\n",
    "    save_acts_stacked = {}\n",
    "\n",
    "    for i in range(num_seeds):\n",
    "        \n",
    "        # load activations\n",
    "        X_untrained = np.load(f'/data/LLMs/data_processed/{d}/acts/X_gpt2-xl-untrained{fe}_m{i}.npz')\n",
    "        gpt2_untrained_dict, gpt2_untrained_bl, gpt2_untrained_bl_perf  = find_best_layer(np.arange(49), noL2_str='', exp=exp, \n",
    "                                                resultsPath=f\"{resultsPath_base}results_{d}/untrained\", niter=1,\n",
    "                                                perf='out_of_sample_r2', feature_extraction=fe, selected_network_indices=lang_indices, \n",
    "                                                subjects=subjects, dataset=d, model_name='gpt2-xl-untrained', seed_number=i)\n",
    "        \n",
    "        X_best_layer = X_untrained[f'layer_{gpt2_untrained_bl}']\n",
    "        \n",
    "        if d == 'pereira':\n",
    "            save_acts_stacked[f\"m{i}_SP_SL_layer_{gpt2_untrained_bl}\"] = np.hstack((X_best_layer, SP_SL))\n",
    "            save_acts_stacked[f\"m{i}_SL_layer_{gpt2_untrained_bl}\"] = np.hstack((X_best_layer, SL))\n",
    "            save_acts_stacked[f\"m{i}_SP_layer_{gpt2_untrained_bl}\"] = np.hstack((X_best_layer, SP))\n",
    "        elif d == 'fedorenko':\n",
    "            save_acts_stacked[f\"m{i}_WP_layer_{gpt2_untrained_bl}\"]  = np.hstack((X_best_layer, WP))\n",
    "        else:\n",
    "            save_acts_stacked[f\"m{i}_POS_WN_layer_{gpt2_untrained_bl}\"]  = np.hstack((X_best_layer, WN_POS))\n",
    "            save_acts_stacked[f\"m{i}_POS_layer_{gpt2_untrained_bl}\"]  = np.hstack((X_best_layer, POS))\n",
    "            save_acts_stacked[f\"m{i}_WN_layer_{gpt2_untrained_bl}\"]  = np.hstack((X_best_layer, WN))\n",
    "            \n",
    "        save_acts[f\"m{i}_layer_{gpt2_untrained_bl}\"] = X_best_layer\n",
    "        \n",
    "    \n",
    "    np.savez(f\"/data/LLMs/data_processed/{d}/acts/X_gpt2-xl-untrained{fe}-pearsonr-best{exp}\", **save_acts)\n",
    "    np.savez(f\"/data/LLMs/data_processed/{d}/acts/X_gpt2-xl-untrained{fe}-var-par{exp}\", **save_acts_stacked)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_brain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
